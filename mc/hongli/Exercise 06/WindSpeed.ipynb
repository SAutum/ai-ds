{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Homework 2: Long Term Behaviour of Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"><b>Instruction:</b> Please upload your executed python code (so plots are visible) together with the other homework problems in a single pdf.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov chains could be used to model a plethora of phenomena that happen in our world. The only assumption that we would have to accept is the fact that what we are trying to model depends only on the last step not on all previous steps (the whole history). \n",
    "\n",
    "For example, Sahin and Sen (2001) model hourly wind speeds in a NW part of Turkey as a Markov chain ${(X_n)}_{n\\in \\mathbb{N}}$ with 7 states representing different wind speed levels. Since in Python arrays are indexed starting from $0$, let us consider the states to be $S=\\{0,1,2,3,4,5,6 \\}$, with $0$ representing the lowest wind speed level. The transition matrix is given by: \n",
    "\n",
    "\\begin{gather*}\n",
    "P=\\begin{array}{cccccccc}\n",
    "& 0 & 1 & 2 & 3 & 4 & 5 & 6 \\\\\n",
    "0 & 0.756 & 0.113 & 0.129 & 0.002 & 0 & 0 & 0\\\\\n",
    "1 & 0.174 & 0.821 & 0.004 & 0.001 & 0 & 0 & 0\\\\\n",
    "2 & 0.141 & 0.001 & 0.776 & 0.082 & 0 & 0 & 0\\\\\n",
    "3 & 0.003 & 0 & 0.192 & 0.753 & 0.052 & 0 & 0\\\\\n",
    "4 & 0 & 0 & 0.002 & 0.227 & 0.735 & 0.036 & 0\\\\\n",
    "5 & 0 & 0 & 0 & 0.007 & 0.367 & 0.604 & 0.022\\\\\n",
    "6 & 0 & 0 & 0 & 0 & 0.053 & 0.158 & 0.789\\\\\n",
    "\\end{array}\n",
    "\\end{gather*}\n",
    "\n",
    "We learned in class the following two facts:\n",
    "\n",
    "<b>Theorem:</b> An irreducible finite state space Markov chain with transition matrix $P$ has a unique stationary distribution $\\pi$ which satisfies\n",
    "\n",
    "\\begin{equation*}\n",
    "\\pi^T P = \\pi^T.\n",
    "\\end{equation*}\n",
    "\n",
    "<b>Theorem:</b> If a Markov chain is irreducible, aperiodic and has a unique stationary distribution $\\pi$, then we have that\n",
    "\n",
    "\\begin{equation*}\n",
    "\\lim_{n\\rightarrow\\infty} {P}^{ n}_{ij} = \\pi_j \\quad \\text{ for all } i,j \\in \\mathcal{S}.\n",
    "\\end{equation*}\n",
    "\n",
    "In the first part of the homework, we will check that this theorem holds by: \n",
    "\n",
    " * Computing $P^{250}$ \n",
    "    \n",
    " * Using the definition of a stationary distribution to compute $\\pi$ that fullfils \n",
    "    $\\pi^T P = \\pi^T$.\n",
    "\n",
    "But first let us import some libraries and read the transition matrix from the .csv file, just like we did in the previous homework: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg\n",
    "import csv\n",
    "\n",
    "# Allows to render plots directly within the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(20180227)\n",
    "\n",
    "csvFile = 'Wind_Speeds.csv'   #specify the path to your csv file\n",
    "\n",
    "P = []\n",
    "with open( csvFile, 'r' ) as file:\n",
    "    reader = csv.reader( file )\n",
    "    for row in reader:\n",
    "        P.append( [ float( prob ) for prob in row ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the matrix was read correctly and is available as an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.756, 0.113, 0.129, 0.002, 0.   , 0.   , 0.   ],\n",
       "       [0.174, 0.821, 0.004, 0.001, 0.   , 0.   , 0.   ],\n",
       "       [0.141, 0.001, 0.776, 0.082, 0.   , 0.   , 0.   ],\n",
       "       [0.003, 0.   , 0.192, 0.753, 0.052, 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.002, 0.227, 0.735, 0.036, 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.007, 0.367, 0.604, 0.022],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.053, 0.158, 0.789]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P=np.array(P)\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "We will check that the theorem holds: \n",
    "\n",
    "<i>a)</i> Compute $P^{250}$ and list at least two of its rows (according to the theorem, for large $n$ all rows should be almost equal to the limiting distribution)\n",
    "\n",
    "<i>Hint</i>: Use the <tt>linalg</tt> package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.24586174e-01, 2.06604292e-01, 3.03930586e-01, 1.31889029e-01,\n",
       "        2.98620155e-02, 2.83256580e-03, 2.95338614e-04],\n",
       "       [3.24586174e-01, 2.06604292e-01, 3.03930586e-01, 1.31889029e-01,\n",
       "        2.98620155e-02, 2.83256580e-03, 2.95338614e-04],\n",
       "       [3.24586174e-01, 2.06604292e-01, 3.03930586e-01, 1.31889029e-01,\n",
       "        2.98620155e-02, 2.83256580e-03, 2.95338614e-04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write your own code here\n",
    "P250 = np.linalg.matrix_power(P,250)\n",
    "P250[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>b)</i> Compute the stationary distribution $\\pi$ by using the definition\n",
    "\n",
    "\\begin{equation*}\n",
    "   \\pi^T P = \\pi^T.\n",
    "\\end{equation*}\n",
    "    \n",
    "Note that in linear algebra (and in most programming languages) all vectors are column vectors and since in the definition we have a row vector $\\pi^T$. If we take the transpose and use the fact that ${(AB)}^T=B^TA^T$, we obtain that $P^T\\pi = \\pi$. \n",
    "\n",
    "Now recall the definition of eigenvalues and eigenvectors: \n",
    "\n",
    "<b>Definition:</b> We say that $\\lambda$ is an eigenvalue and $v$ is the corresponding eigenvector for matrix $A$ if \n",
    "\n",
    "$$Av = \\lambda v$$ \n",
    "holds true. \n",
    "\n",
    "Hence, for a stationary distribution $\\lambda=1$ is an eigenvalue to the matrix $P^T$ with eigenvector $v=\\pi$. Therefore, in order to quickly find the stationary distribution, we can look at the positive eigenvectors that correspond to the eigenvalue $1$ for the matrix $P^T$ and we just normalize it so that the entries add up to $1$ (since it has to be a distribution or probability vector).\n",
    "\n",
    "<i>Hint</i>: Use the <tt>linalg</tt> package to find the eigenvalues and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      " 2.98620155e-02 2.83256580e-03 2.95338614e-04]\n",
      "[3.24586174e-01 2.06604292e-01 3.03930586e-01 1.31889029e-01\n",
      " 2.98620155e-02 2.83256580e-03 2.95338614e-04]\n"
     ]
    }
   ],
   "source": [
    "## Write your own code here\n",
    "# find the eigenvalues and enigenvectors of the matrix P\n",
    "eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "station_dist = (eigenvectors.T)[np.where(np.abs(eigenvalues - 1) < 1e-8)].squeeze()\n",
    "station_dist /= station_dist.sum()\n",
    "print(station_dist)\n",
    "print(station_dist@P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "We had actually another important result: \n",
    "\n",
    "<b>Theorem:</b> For any finite irreducible Markov chain we have that the stationary distribution $\\pi$ satisfies\n",
    "\n",
    "\\begin{equation*}\n",
    "\\pi_j=\\frac{1}{\\mathbb{E}[T_j\\,| \\,X_0=j]} \\quad \\text{ for all } j \\in \\mathcal{S} \n",
    "\\end{equation*}\n",
    "\n",
    "where $T_j = \\min\\{n>0:X_n=j \\}$ denotes the first visiting time of state $j$ after having started in $j$ at time 0.\n",
    "\n",
    "Hence, in order to find the expected return time to state $j$, we just have to compute $1/\\pi_j$.\n",
    "\n",
    "In this $2^{nd}$ part of the homework, we will check that this theorem holds for state $0$. From the previous Python homework, we know how to simulate a Markov chain using the transition matrix. So, simulate $N=10^5$ Markov Chains with transition matrix $P$ that start at $0$. Each Markov chain should be simulated until state $0$ is reached again (so you do not actually have to run each Markov chain for many steps). For each of the $N$ Markov chains, memorize how long it took to get back to state $0$. In the end, a good estimate of $\\mathbb{E}[T_0 \\,| \\, X_0=0]$ will be the average of all of those times. Because of the above theorem, the estimate should be close to $1/\\pi_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate:3.1061\n",
      "theoretical:3.0808459523258724\n"
     ]
    }
   ],
   "source": [
    "## Write your own code here\n",
    "n = int(1e5)\n",
    "return_times = []\n",
    "for i in range(n):\n",
    "    state = 0\n",
    "    return_time = 0\n",
    "    while True:\n",
    "        state = np.random.choice( range( P.shape[0] ), p=P[state] )\n",
    "        return_time += 1\n",
    "        if state == 0:\n",
    "            return_times.append(return_time)\n",
    "            break\n",
    "\n",
    "return_times = np.array(return_times)\n",
    "print(\"estimate:{}\".format(return_times.mean()))\n",
    "print(\"theoretical:{}\".format(1/station_dist[0]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
