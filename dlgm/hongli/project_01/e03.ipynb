{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\"there are many available options for these design choices, leading to various trade-offs in terms of the learned representation\"\n",
    "\n",
    "- Learning the `log variance` instead of variance of the latent space encourages learning stability:\n",
    "    https://stats.stackexchange.com/questions/353220/why-in-variational-auto-encoder-gaussian-variational-family-we-model-log-sig\n",
    "- Expand the standard VAE to a beta one. Maybe something interesting would come up\n",
    "- VAE learns representations in a small latent space. Why don't we try squeezing resnet structure inside it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE model\n",
    "\n",
    "interestingly:\n",
    "\n",
    "In forward pass, there is a step of sampling $\\varepsilon$ from standard normal \n",
    "distribution. In my opinion it turns the stochastic process to a deterministic\n",
    "one: from all possible generated images $\\hat{x}$ given input image $x$, \n",
    "we sample only one of them, using (more or less) normally distributed latent \n",
    "variables. Without sampling the backprop won't work (that's also why we need \n",
    "reparametrization trick)\n",
    "\n",
    "In analogy, in reinforcement learning with MDP model, each time we sample one\n",
    "sequence (so-called episode) till termination. Out of all possible outcomes,\n",
    "we see only one outcome in one episode. And we trained the model based on this\n",
    "outcome.\n",
    "\n",
    "This makes me wonder: in VAE, if we **reuse** the image we trained already, \n",
    "could we dig more information from it simply by resampling? \n",
    "The resampled image from the latent space\n",
    "is most likely different from the previous one, with similarities.\n",
    "And the cross-entropy value should be different.\n",
    "\n",
    "Furthermore, in classification problem, when we choose the most probable class\n",
    "from the softmaxed linear output layer as the label, we are also \"sampling\", \n",
    "i.e. turning stochastic into deterministic. \n",
    "However, in the learning phase we kept the stochasticity in cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalAutoEncoder(nn.Module):\n",
    "    \"\"\" implementation of the Variational AutoEncoder\n",
    "\n",
    "    Args:\n",
    "        - device: the device to run the model on\n",
    "        - input_size: the size of the input data\n",
    "        - hidden_size: the size of the hidden layer\n",
    "        - z_space_size: the size of the latent space\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device,\n",
    "                 input_size: int, z_space_size: int,\n",
    "                 hidden_size: int = 256,\n",
    "                 ) -> None:\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        # encoder: from x to two channels: mean and log_var\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_size, z_space_size),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "        # mean and logvariance layers from the input to the latent space\n",
    "        self.mean_layer = nn.Linear(z_space_size, 2)\n",
    "        self.logvar_layer = nn.Linear(z_space_size, 2)\n",
    "\n",
    "        # decoder: from z to x^hat\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, z_space_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(z_space_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "            # nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    # reparameterization trick, the randomness is pushed outside the network\n",
    "    # z = mu + sigma * epsilon, where epsilon ~ N(0, 1)\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        # similar to mean, epsilon is in fact a vector of\n",
    "        # size of the latent space\n",
    "        epsilon = torch.randn_like(mean).to(self.device)\n",
    "        var = torch.exp(0.5 * log_var)\n",
    "        # return the latent space vector\n",
    "            # here the variance is also modeled as a vector, mathematically it\n",
    "            # should be a diagonal matrix and epsilon should be matrix\n",
    "            # multiplied with the variance matrix\n",
    "        z = mean + var * epsilon\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        # put everything together\n",
    "        x = self.encode(x)\n",
    "        mean = self.mean_layer(x)\n",
    "        log_var = self.logvar_layer(x)\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input space size:  torch.Size([1, 784])\n",
      "latent space size:  torch.Size([1, 2])\n",
      "output space size:  torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "# test the dimensionality of the model\n",
    "model = VariationalAutoEncoder(device, 784, 2)\n",
    "model.to(device)\n",
    "test_tensor = torch.randn(1, 784).to(device)\n",
    "print(\"input space size: \", test_tensor.shape)\n",
    "print(\"latent space size: \", model(test_tensor)[1].shape)\n",
    "output = model(test_tensor)\n",
    "print(\"output space size: \", output[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "reconstruction: the ability to copy the original image\n",
    "\n",
    "$-log($"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction loss ()) + beta KL divergence (regularization)\n",
    "def loss_function():\n",
    "    # reconstruction loss =\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
