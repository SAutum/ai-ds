{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise sheet 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This assignment was done by group of ID*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<YOUR_GROUP_ID> e.g. 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<YOUR_GROUP_DAY> Tuesday or Wednesday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Strided convolution (1 point)\n",
    "In the lecture you learned about the convolution operation. It was also introduced as a sliding window operation. The stride, in this intuition, is the step size of the sliding window.\n",
    "In this exercise, you will implement a 2d convolutional layer with the additional option to use a stride. The strided convoultion $x*k$ for a given 2d input signal $x \\in \\mathbb{R}^{H \\times W}$, a kernel $k  \\in \\mathbb{R}^{2k+1 \\times 2k+1}$ and a stride $s$ is defined as follows:\n",
    "\n",
    "$$(x * k)(i, j) = \\sum_{m=-k}^{k} \\sum_{n=-k}^{k} x(is + m, js + n) \\cdot k(m, n)$$\n",
    "\n",
    "The following figure illustrates the strided convolution with a stride of 2:\n",
    "\n",
    "![Convolution with stride 2](https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to extend the code given in the lecture to include the stride parameter. The function should have the following signature:\n",
    "\n",
    "```python\n",
    "def conv2d(self: Tensor, kernel: Tensor, stride = 1: int, padding = None: int) -> Tensor:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Tensor import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# striding in numpy:\n",
    "np.arange(0, 15, 1)[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(self: Tensor, kernel: Tensor, stride: int = 1, padding: int = None) -> Tensor:\n",
    "    kernel_size = kernel.data.shape[-1]\n",
    "\n",
    "    # apply padding to the input tensor(self) if required\n",
    "    if padding == None:\n",
    "        padding = kernel_size//2\n",
    "    input_data = self.pad2d(padding).data\n",
    "\n",
    "    # compute the dimensions of the output\n",
    "    h_in, w_in = self.data.shape[-2], self.data.shape[-1]\n",
    "    h_out = (h_in + 2 * padding - kernel_size)//stride + 1\n",
    "    w_out = (w_in + 2 * padding - kernel_size)//stride + 1\n",
    "\n",
    "    # initialize output data, the last two dims are the height and width\n",
    "    output_data = np.zeros(self.data.shape[:-2] + (h_out, w_out))\n",
    "\n",
    "    # loop over kernel to update the value of output_data\n",
    "    for m in range(kernel_size):\n",
    "        for n in range(kernel_size):\n",
    "            output_data += input_data[\n",
    "                                    m:(h_out*stride+m):stride,\n",
    "                                    n:(w_out*stride+n):stride\n",
    "                                    ] \\\n",
    "                            * kernel.data[m, n]\n",
    "\n",
    "    out = Tensor(output_data)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as imageio\n",
    "url = 'https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n",
    "lena = imageio.imread(url)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# make gray-scale image\n",
    "lena_bw = Image.fromarray(lena).convert('L')\n",
    "lena_np = np.array(lena_bw).astype(np.float32) / 255.0\n",
    "lena_tensor = Tensor(data=lena_np)\n",
    "smoothing_kernel = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]]).astype(np.float32) / 9\n",
    "smoothing_kernel = Tensor(data=smoothing_kernel)\n",
    "padding = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional tests\n",
    "Your implementation should pass the following functional tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stride: 1 - Correct\n",
      "Stride: 2 - Correct\n",
      "Stride: 4 - Correct\n",
      "Stride: 8 - Correct\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "lena_torch = torch.tensor(lena_np)\n",
    "smoothing_kernel_torch = torch.tensor(smoothing_kernel.data)\n",
    "\n",
    "for stride in [1, 2, 4, 8]:\n",
    "    output_torch = F.conv2d(lena_torch[None, None, ...], smoothing_kernel_torch[None, None, ...], stride=stride, padding=padding if padding is not None else smoothing_kernel.data.shape[-1] // 2)\n",
    "    output = conv2d(lena_tensor, smoothing_kernel, stride, padding)\n",
    "    assert output.data.shape == output_torch.squeeze().numpy().shape, f\"Shape mismatch: {output.data.shape} != {output_torch.squeeze().numpy().shape}\"\n",
    "    np.testing.assert_allclose(output.data, output_torch.squeeze().numpy(), rtol=1e-5)\n",
    "    print(f\"Stride: {stride} - Correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance test\n",
    "This test is just for your interest. You can use it to compare different implementations you come up with or against the pytorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = np.random.rand(1000, 1000).astype(np.float32)\n",
    "data_tensor = Tensor(data=data)\n",
    "kernel = np.random.rand(3, 3).astype(np.float32)\n",
    "kernel_tensor = Tensor(data=kernel)\n",
    "stride = 2\n",
    "padding = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11 ms ± 13.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## Your implementation\n",
    "%timeit conv2d(data_tensor, kernel_tensor, stride, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 µs ± 678 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "## PyTorch implementation\n",
    "%timeit F.conv2d(torch.tensor(data[None, None, ...]), torch.tensor(kernel[None, None, ...]), stride=stride, padding=padding if padding is not None else kernel.shape[-1] // 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) 2d transposed convolution (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will implement a 2d transposed convolution operation $x *^T k$ for a given 2d input signal $x \\in \\mathbb{R}^{H \\times W}$ and a kernel $k \\in \\mathbb{R}^{2k + 1 \\times 2k+1}$ with unit stride and no padding.\n",
    "\n",
    "The 2d transposed convolution can be understood as a sliding window operation over the elements in the input signal $x$. The whole filter $k$ is applied to each element of the input signal $x$ by multiplying the filter with the element under consideration and adding the result to the output tensor at the corresponding position.\n",
    "To implement the transposed convolution, you can initialize the output tensor with zeros and then iteratevely add the result up.\n",
    "\n",
    "The following figure illustrates the transposed convolution in terms of an example\n",
    "\n",
    "![Transposed convolution](https://www.researchgate.net/profile/Md-Afif-Al-Mamun-2/publication/358607641/figure/fig4/AS:1123654414934027@1644911497422/6-Transposed-convolution-operation-6-shows-transposed-convolution-of-a-2-2-input.ppm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to implement the transposed convolution operation. The function should have the following signature:\n",
    "\n",
    "```python\n",
    "def conv_transpose2d(self: Tensor, kernel: Tensor) -> Tensor:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose2d(self: Tensor, kernel: Tensor) -> Tensor:\n",
    "    kernel_size = kernel.data.shape[-1]\n",
    "    # get the width and height of the input\n",
    "    h_in, w_in = self.data.shape[-2:]\n",
    "\n",
    "    # compute the output shape\n",
    "    out_shape = self.data.shape[:-2] \\\n",
    "                + (h_in + kernel_size - 1, w_in + kernel_size - 1)\n",
    "\n",
    "    # initialize the output data\n",
    "    out_data = np.zeros(out_shape)\n",
    "\n",
    "    # loop over kernel to update out_data\n",
    "    for m in range(kernel_size):\n",
    "        for n in range(kernel_size):\n",
    "            out_data[m:(h_in + m), n:(w_in + n)] += self.data*kernel.data[m, n]\n",
    "\n",
    "    # wrap the output to a tensor\n",
    "    out = Tensor(out_data)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional tests\n",
    "Your implementation should pass the following functional tests, which test the shape of the output and also the numerical values of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size: (3, 3), Kernel size: (1, 1) - Correct\n",
      "Input size: (3, 3), Kernel size: (2, 2) - Correct\n",
      "Input size: (3, 3), Kernel size: (3, 3) - Correct\n",
      "Input size: (3, 3), Kernel size: (4, 4) - Correct\n",
      "Input size: (4, 4), Kernel size: (1, 1) - Correct\n",
      "Input size: (4, 4), Kernel size: (2, 2) - Correct\n",
      "Input size: (4, 4), Kernel size: (3, 3) - Correct\n",
      "Input size: (4, 4), Kernel size: (4, 4) - Correct\n",
      "Input size: (5, 5), Kernel size: (1, 1) - Correct\n",
      "Input size: (5, 5), Kernel size: (2, 2) - Correct\n",
      "Input size: (5, 5), Kernel size: (3, 3) - Correct\n",
      "Input size: (5, 5), Kernel size: (4, 4) - Correct\n",
      "Input size: (6, 6), Kernel size: (1, 1) - Correct\n",
      "Input size: (6, 6), Kernel size: (2, 2) - Correct\n",
      "Input size: (6, 6), Kernel size: (3, 3) - Correct\n",
      "Input size: (6, 6), Kernel size: (4, 4) - Correct\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "for input_size in [(3, 3), (4, 4), (5, 5), (6, 6)]:\n",
    "    for kernel_size in [(1, 1), (2, 2), (3, 3), (4, 4)]:\n",
    "        data = np.random.rand(*input_size).astype(np.float32)\n",
    "        data_tensor = Tensor(data=data)\n",
    "        kernel = np.random.rand(*kernel_size).astype(np.float32)\n",
    "        kernel_tensor = Tensor(data=kernel)\n",
    "\n",
    "        output_torch = F.conv_transpose2d(torch.tensor(data[None, None, ...]), torch.tensor(kernel[None, None, ...]))\n",
    "\n",
    "        output = conv_transpose2d(data_tensor, kernel_tensor)\n",
    "        assert output.data.shape == output_torch.squeeze().numpy().shape, f\"Shape mismatch: {output.data.shape} != {output_torch.squeeze().numpy().shape}\"\n",
    "        np.testing.assert_allclose(output.data, output_torch.squeeze().numpy(), rtol=1e-5)\n",
    "        print(f\"Input size: {input_size}, Kernel size: {kernel_size} - Correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = np.random.rand(1000,1000).astype(np.float32)\n",
    "data_tensor = Tensor(data=data)\n",
    "kernel = np.random.rand(11,11).astype(np.float32)\n",
    "kernel_tensor = Tensor(data=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 2.37 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit conv_transpose2d(data_tensor, kernel_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 ms ± 467 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit F.conv_transpose2d(torch.tensor(data[None, None, ...]), torch.tensor(kernel[None, None, ...]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 2. Theory (2 point)\n",
    "\n",
    "Derive the formula for the output shape of a convolutional layer. Assume the input shape is $H \\times W$ and the convolutional layer has a kernel of dimension $F \\times F$. The stride is $S$ and the padding is $P$. (i.e. come up with a formula that gives you $H'$ and $W'$ for the output shape $H' \\times W'$ of the convolutional layer in terms of $H$, $W$, $F$, $S$ and $P$ and explain why it is correct)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
