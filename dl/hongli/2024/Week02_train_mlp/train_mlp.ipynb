{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General\n",
    "\n",
    "In this exercise we will train various small MLPs on predicting IQ from a few other characteristics.\n",
    "We will explore the concepts of \n",
    "- mini-batch training and \n",
    "- training/validation/test split of the data.\n",
    "\n",
    "You will have to fill in the gaps in the code, run the experiments and prepare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batch Training\n",
    "\n",
    "First, here is the idea behind mini-batch training:\n",
    "For larger datasets it is computationally disadvantageous to compute gradients for all training examples and then make a full gradient descent step. Instead, we subsample a mini-batch, i.e. a subset of training examples. For them, we compute the forward and backward pass and make a gradient step. One pass through all examples in the training set is called an epoch.\n",
    "\n",
    "In pseudo-code, we do the following:\n",
    "\n",
    "- For epoch=1,...\n",
    "    - Choose minibatches mb_1,...,mb_k that cover the full training set\n",
    "    - For each minibath mb = {(x'_1,y'_1),...,(x'_l,y'_l)}\n",
    "        - Compute gradients of loss for each element (x'_i, y'_i) w.r.t. each trainable parameter\n",
    "        - Make update step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split\n",
    "\n",
    "In order to assess generalization error, we split the dataset into a \n",
    "- training subset (typically ~70 - 80%) that we train on\n",
    "- a validation subset (typically ~10 - 20%) that we use choose best hyperarameters and pick the right number of training iterations for early stopping\n",
    "- a test subset (typically ~10%) to estimate generalization error.\n",
    "\n",
    "**Important**: Never use the test set to tune your model! It cannot influence model selection or training in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs</th>\n",
       "      <th>gpa</th>\n",
       "      <th>iq</th>\n",
       "      <th>gender</th>\n",
       "      <th>concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.940</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.292</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.643</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.470</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.882</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   obs    gpa   iq  gender  concept\n",
       "0    1  7.940  111       2       67\n",
       "1    2  8.292  107       2       43\n",
       "2    3  4.643  100       2       52\n",
       "3    4  7.470  107       2       66\n",
       "4    5  8.882  114       1       58"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"gpa_iq.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    \"\"\"\n",
    "    Added `exp` and `pow`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, _children=(), operation=\"\", label=\"\"):\n",
    "        self.data = data\n",
    "        self._prev = set(_children)\n",
    "        self._operation = operation\n",
    "        self._label = label\n",
    "\n",
    "        # because we assume that the value doesn't affect the\n",
    "        # loss function by default, thus the slope is 0.0\n",
    "        self.grad = 0.0\n",
    "\n",
    "        # This will store a function which will calculate the\n",
    "        # local derivative according to the operation and store\n",
    "        # in the `self.grad` variable.\n",
    "        self._backward = lambda : None\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (np.exp(2*x) - 1) / (np.exp(2*x) + 1)\n",
    "        out = Value(t, (self,), \"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - t ** 2) * out.grad # chain rule here too!\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):\n",
    "            node._backward()\n",
    "\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = Value(other) if not isinstance(other, Value) else other\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        other = Value(other) if not isinstance(other, Value) else other\n",
    "        out =  Value(self.data / other.data, (self, other), '/')\n",
    "        def _backward():\n",
    "            self.grad += (1.0 / other.data) * out.grad\n",
    "            other.grad += self.data * (-1.0 / other.data**2) * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = Value(other) if not isinstance(other, Value) else other\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        other = Value(other) if not isinstance(other, Value) else other\n",
    "        out = Value(self.data - other.data, (self, other), '-')\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += -1.0 * out.grad\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __radd__(self, other):\n",
    "        return self + other\n",
    "\n",
    "    def __rmul__(self, other):\n",
    "        return self * other\n",
    "\n",
    "    def __rsub__(self, other):\n",
    "        return self - other\n",
    "\n",
    "    def __rtruediv__(self, other):\n",
    "        return self / other\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"Only int/float can be used\"\n",
    "        out = Value(self.data ** other, (self, ), f'**{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other * (self.data ** (other - 1)) * out.grad # chain rule\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neuron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    \"\"\"\n",
    "    Making a new function `parameters` which will return ONLY the weights + bias.\n",
    "    \"\"\"\n",
    "    def __init__(self, nin, activate=True):\n",
    "        self.w = [Value(np.random.uniform(-1, 1), label=f'w{i}') for i in range(nin)]\n",
    "        self.b = Value(np.random.uniform(-1, 1), label='b')\n",
    "        self.activate = activate\n",
    "\n",
    "    def __call__(self, x):\n",
    "        assert len(x) == len(self.w)\n",
    "        out = sum(xi*wi for xi, wi in zip(x, self.w)) + self.b\n",
    "        if self.activate:\n",
    "            out = out.tanh()\n",
    "        return out\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    Added a new function `parameters` which will fetch all params from all neurons\n",
    "    and then make a flat list of all params\n",
    "    \"\"\"\n",
    "    def __init__(self, nin, nout, activated=True):\n",
    "        self.neurons = [Neuron(nin,activated) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        activateds = [n(x) for n in self.neurons]\n",
    "        return activateds[0] if len(activateds) == 1 else activateds\n",
    "\n",
    "    def parameters(self):\n",
    "        params = [] # the flat list of params\n",
    "        for neuron in self.neurons:\n",
    "            ps = neuron.parameters()\n",
    "            params.extend(ps)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "    Added a new function `parameters` to get the parameters from all layers and\n",
    "    then flatten it.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nin: int, nouts: List):\n",
    "        sizes = [nin] + nouts\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(len(nouts)):\n",
    "            activated = True if i != len(nouts) - 1 else False # last layer should not be activated\n",
    "            layer = Layer(sizes[i], sizes[i + 1], activated)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        params = [] # the flat list of params\n",
    "        for layer in self.layers:\n",
    "            ps = layer.parameters()\n",
    "            params.extend(ps)\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training - mini batch + train/val/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of data points, Train: 62, Val: 8, Test: 8\n",
      "Sum: 78\n",
      "Epoch 1, Training Loss: 5.5589\n",
      "Validation Loss: 3.9243\n",
      "Epoch 2, Training Loss: 3.4085\n",
      "Validation Loss: 2.2992\n",
      "Epoch 3, Training Loss: 2.0139\n",
      "Validation Loss: 1.2830\n",
      "Epoch 4, Training Loss: 1.1453\n",
      "Validation Loss: 0.6857\n",
      "Epoch 5, Training Loss: 0.6346\n",
      "Validation Loss: 0.3558\n",
      "Epoch 6, Training Loss: 0.3488\n",
      "Validation Loss: 0.1820\n",
      "Epoch 7, Training Loss: 0.1934\n",
      "Validation Loss: 0.0933\n",
      "Epoch 8, Training Loss: 0.1101\n",
      "Validation Loss: 0.0494\n",
      "Epoch 9, Training Loss: 0.0655\n",
      "Validation Loss: 0.0285\n",
      "Epoch 10, Training Loss: 0.0417\n",
      "Validation Loss: 0.0192\n",
      "Epoch 11, Training Loss: 0.0290\n",
      "Validation Loss: 0.0155\n",
      "Epoch 12, Training Loss: 0.0222\n",
      "Validation Loss: 0.0145\n",
      "Epoch 13, Training Loss: 0.0185\n",
      "Validation Loss: 0.0147\n",
      "Epoch 14, Training Loss: 0.0165\n",
      "Validation Loss: 0.0153\n",
      "Epoch 15, Training Loss: 0.0154\n",
      "Validation Loss: 0.0159\n",
      "Epoch 16, Training Loss: 0.0148\n",
      "Validation Loss: 0.0166\n",
      "Epoch 17, Training Loss: 0.0145\n",
      "Validation Loss: 0.0171\n",
      "Epoch 18, Training Loss: 0.0143\n",
      "Validation Loss: 0.0175\n",
      "Epoch 19, Training Loss: 0.0142\n",
      "Validation Loss: 0.0178\n",
      "Epoch 20, Training Loss: 0.0142\n",
      "Validation Loss: 0.0181\n",
      "Epoch 21, Training Loss: 0.0141\n",
      "Validation Loss: 0.0182\n",
      "Epoch 22, Training Loss: 0.0141\n",
      "Validation Loss: 0.0184\n",
      "Epoch 23, Training Loss: 0.0141\n",
      "Validation Loss: 0.0184\n",
      "Epoch 24, Training Loss: 0.0140\n",
      "Validation Loss: 0.0185\n",
      "Epoch 25, Training Loss: 0.0140\n",
      "Validation Loss: 0.0185\n",
      "Epoch 26, Training Loss: 0.0140\n",
      "Validation Loss: 0.0185\n",
      "Epoch 27, Training Loss: 0.0140\n",
      "Validation Loss: 0.0185\n",
      "Epoch 28, Training Loss: 0.0140\n",
      "Validation Loss: 0.0185\n",
      "Epoch 29, Training Loss: 0.0139\n",
      "Validation Loss: 0.0184\n",
      "Epoch 30, Training Loss: 0.0139\n",
      "Validation Loss: 0.0184\n",
      "Epoch 31, Training Loss: 0.0139\n",
      "Validation Loss: 0.0184\n",
      "Epoch 32, Training Loss: 0.0139\n",
      "Validation Loss: 0.0183\n",
      "Epoch 33, Training Loss: 0.0139\n",
      "Validation Loss: 0.0183\n",
      "Epoch 34, Training Loss: 0.0138\n",
      "Validation Loss: 0.0182\n",
      "Epoch 35, Training Loss: 0.0138\n",
      "Validation Loss: 0.0182\n",
      "Epoch 36, Training Loss: 0.0138\n",
      "Validation Loss: 0.0182\n",
      "Epoch 37, Training Loss: 0.0138\n",
      "Validation Loss: 0.0181\n",
      "Epoch 38, Training Loss: 0.0138\n",
      "Validation Loss: 0.0181\n",
      "Epoch 39, Training Loss: 0.0137\n",
      "Validation Loss: 0.0180\n",
      "Epoch 40, Training Loss: 0.0137\n",
      "Validation Loss: 0.0180\n",
      "Epoch 41, Training Loss: 0.0137\n",
      "Validation Loss: 0.0179\n",
      "Epoch 42, Training Loss: 0.0137\n",
      "Validation Loss: 0.0179\n",
      "Epoch 43, Training Loss: 0.0137\n",
      "Validation Loss: 0.0179\n",
      "Epoch 44, Training Loss: 0.0137\n",
      "Validation Loss: 0.0178\n",
      "Epoch 45, Training Loss: 0.0136\n",
      "Validation Loss: 0.0178\n",
      "Epoch 46, Training Loss: 0.0136\n",
      "Validation Loss: 0.0177\n",
      "Epoch 47, Training Loss: 0.0136\n",
      "Validation Loss: 0.0177\n",
      "Epoch 48, Training Loss: 0.0136\n",
      "Validation Loss: 0.0176\n",
      "Epoch 49, Training Loss: 0.0136\n",
      "Validation Loss: 0.0176\n",
      "Epoch 50, Training Loss: 0.0135\n",
      "Validation Loss: 0.0176\n",
      "Epoch 51, Training Loss: 0.0135\n",
      "Validation Loss: 0.0175\n",
      "Epoch 52, Training Loss: 0.0135\n",
      "Validation Loss: 0.0175\n",
      "Epoch 53, Training Loss: 0.0135\n",
      "Validation Loss: 0.0174\n",
      "Epoch 54, Training Loss: 0.0135\n",
      "Validation Loss: 0.0174\n",
      "Epoch 55, Training Loss: 0.0135\n",
      "Validation Loss: 0.0173\n",
      "Epoch 56, Training Loss: 0.0134\n",
      "Validation Loss: 0.0173\n",
      "Epoch 57, Training Loss: 0.0134\n",
      "Validation Loss: 0.0173\n",
      "Epoch 58, Training Loss: 0.0134\n",
      "Validation Loss: 0.0172\n",
      "Epoch 59, Training Loss: 0.0134\n",
      "Validation Loss: 0.0172\n",
      "Epoch 60, Training Loss: 0.0134\n",
      "Validation Loss: 0.0171\n",
      "Epoch 61, Training Loss: 0.0134\n",
      "Validation Loss: 0.0171\n",
      "Epoch 62, Training Loss: 0.0133\n",
      "Validation Loss: 0.0171\n",
      "Epoch 63, Training Loss: 0.0133\n",
      "Validation Loss: 0.0170\n",
      "Epoch 64, Training Loss: 0.0133\n",
      "Validation Loss: 0.0170\n",
      "Epoch 65, Training Loss: 0.0133\n",
      "Validation Loss: 0.0169\n",
      "Epoch 66, Training Loss: 0.0133\n",
      "Validation Loss: 0.0169\n",
      "Epoch 67, Training Loss: 0.0133\n",
      "Validation Loss: 0.0169\n",
      "Epoch 68, Training Loss: 0.0132\n",
      "Validation Loss: 0.0168\n",
      "Epoch 69, Training Loss: 0.0132\n",
      "Validation Loss: 0.0168\n"
     ]
    }
   ],
   "source": [
    "# Extract features and target\n",
    "X = data[['gpa', 'gender', 'concept']].values\n",
    "y = data['iq'].values.astype(float)\n",
    "\n",
    "# normalize features and target\n",
    "X /= X.max(axis=0)\n",
    "y /= 100.0\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)  # For numpy operations if needed\n",
    "\n",
    "# Generate shuffled indices\n",
    "indices = list(range(len(X)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "# Split the indices into 80% train, 10% validation, 10geschigeschiin order provided by indices.\n",
    "train_end = int(0.8 * len(indices))\n",
    "val_end = int(0.9 * len(indices))\n",
    "\n",
    "train_indices = indices[:train_end]\n",
    "val_indices = indices[train_end:val_end]\n",
    "test_indices = indices[val_end:]\n",
    "\n",
    "X_train, y_train = X[train_indices], y[train_indices] # 80% of the indices, from 0 to train_end\n",
    "X_val, y_val = X[val_indices], y[val_indices] # 10% of the indices, from train_end to val_end\n",
    "X_test, y_test = X[test_indices], y[test_indices] # 10% of the indices, from val_end to the end\n",
    "print(f\"No. of data points, Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "print(f\"Sum: {len(X_train) + len(X_val) + len(X_test)}\")\n",
    "\n",
    "# Define the model\n",
    "model = MLP(3, [5, 10, 10, 1]) # to be filled. Try different architectures up to three hidden layers.\n",
    "\n",
    "# Get the parameters\n",
    "parameters = model.parameters()\n",
    "\n",
    "# Hyperparameters\n",
    "lr = 1e-4 # To be filled. Try different learning rates.\n",
    "num_epochs = 80  # To be filled. Try different number of epochs.\n",
    "batch_size = 8\n",
    "\n",
    "# Lists to store losses for plotting\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "num_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size # the starting index of the batch\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(X_train)) # the ending index of the batch, the last one will be len(X_train)\n",
    "        # Get the batch\n",
    "        X_batch = X_train[start_idx:end_idx]\n",
    "        y_batch = y_train[start_idx:end_idx]\n",
    "        batch_loss = []\n",
    "\n",
    "        # Calculate the loss for the batch\n",
    "        for x_i, y_i in zip(X_batch, y_batch):\n",
    "            x_values = [Value(x) for x in x_i]\n",
    "            y_pred = model(x_values)\n",
    "            loss = (y_pred - Value(y_i)) ** 2\n",
    "            total_loss += loss.data\n",
    "            batch_loss.append(loss) # append single loss to batch loss\n",
    "        batch_loss = sum(batch_loss) # sum all the losses in the batch\n",
    "\n",
    "        # Backpropagate the loss\n",
    "        for p in parameters: # first zero out the gradients, since all is +=\n",
    "            p.grad = 0.0\n",
    "        batch_loss.backward() # backpropagate the loss\n",
    "\n",
    "        # Update the parameters using their gradients and learning rate per batch\n",
    "        for p in parameters:\n",
    "            p.data -= lr * p.grad\n",
    "\n",
    "\n",
    "    avg_loss = total_loss / len(X_train)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_loss = 0.0\n",
    "    for x_i, y_i in zip(X_val, y_val):\n",
    "        x_values = [Value(x) for x in x_i]\n",
    "        y_pred = model(x_values)\n",
    "        loss = (y_pred - Value(y_i)) ** 2\n",
    "        val_loss += loss.data\n",
    "\n",
    "    avg_val_loss = val_loss / len(X_val)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Plot the training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# After training, evaluate on the test set using MLP\n",
    "mlp_test_loss = 0.0\n",
    "for x_i, y_i in zip(X_test, y_test):\n",
    "    x_values = [Value(x) for x in x_i]\n",
    "    y_pred = model(x_i)\n",
    "    loss = (y_pred - y_i) ** 2\n",
    "    mlp_test_loss += loss.data\n",
    "\n",
    "avg_mlp_test_loss = mlp_test_loss / len(X_test)\n",
    "print(f\"MLP Test Loss (MSE): {avg_mlp_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results with linear regression by evaluating how your MLP predictions align with those generated by a simple Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Coefficients (theta):\n",
      "[0.36610459 0.11992817 0.10928905 0.67582417]\n",
      "Linear Regression Test Loss (MSE): 0.0038\n",
      "\n",
      "Comparison of Test Losses:\n",
      "MLP Test Loss (MSE): 0.0146\n",
      "Linear Regression Test Loss (MSE): 0.0038\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# Linear Regression Comparison\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Add a column of ones to X_train and X_test for the intercept term\n",
    "ones_train = np.ones((X_train.shape[0], 1))\n",
    "X_train_lr = np.hstack((X_train, ones_train))\n",
    "\n",
    "ones_test = np.ones((X_test.shape[0], 1))\n",
    "X_test_lr = np.hstack((X_test, ones_test))\n",
    "\n",
    "# Compute theta using the closed-form solution on the training set\n",
    "XT_X = np.matmul(X_train_lr.T, X_train_lr)\n",
    "XT_X_inv = np.linalg.inv(XT_X)\n",
    "XT_y = np.matmul(X_train_lr.T, y_train)\n",
    "theta = np.matmul(XT_X_inv, XT_y)\n",
    "\n",
    "print(\"\\nLinear Regression Coefficients (theta):\")\n",
    "print(theta)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_lr = np.matmul(X_test_lr, theta)\n",
    "\n",
    "# Compute Mean Squared Error for Linear Regression on the test set\n",
    "mse_lr = np.mean((y_pred_lr - y_test) ** 2)\n",
    "print(f\"Linear Regression Test Loss (MSE): {mse_lr:.4f}\")\n",
    "\n",
    "# Compare with MLP Test Loss\n",
    "print(\"\\nComparison of Test Losses:\")\n",
    "print(f\"MLP Test Loss (MSE): {avg_mlp_test_loss:.4f}\")\n",
    "print(f\"Linear Regression Test Loss (MSE): {mse_lr:.4f}\")\n",
    "\n",
    "labels = ['MLP', 'Linear Regression']\n",
    "test_losses = [avg_mlp_test_loss, mse_lr]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.bar(labels, test_losses, color=['blue', 'orange'])\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('Comparison of Test Losses')\n",
    "for i, v in enumerate(test_losses):\n",
    "    plt.text(i, v + 0.01 * max(test_losses), f\"{v:.4f}\", ha='center', fontweight='bold')\n",
    "plt.ylim(0, max(test_losses) * 1.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
