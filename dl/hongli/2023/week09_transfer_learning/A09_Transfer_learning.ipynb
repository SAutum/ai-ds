{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg6rmjOp3SP3"
   },
   "source": [
    "HHU Deep Learning, WS2023/24, 08.12.2022\n",
    "\n",
    "Lecture: Prof. Dr. Markus Kollmann\n",
    "\n",
    "Exercises: Nikolas Adaloglou, Felix Michels\n",
    "\n",
    "# Assignment 9 - Transfer Learning in Image Classification\n",
    "\n",
    "---\n",
    "\n",
    "Submit the solved notebook (not a zip) with your full name plus assignment number for the filename as an indicator, e.g `max_mustermann_a1.ipynb` for assignment 1. If we feel like you have genuinely tried to solve the exercise, you will receive 1 point for this assignment, regardless of the quality of your solution.\n",
    "\n",
    "## <center> DUE FRIDAY 15.12.2023 2:30 pm </center>\n",
    "\n",
    "Drop-off link: [https://uni-duesseldorf.sciebo.de/s/zDoBcOZiMPNar50](https://uni-duesseldorf.sciebo.de/s/zDoBcOZiMPNar50)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Y2pSVIa3mnh"
   },
   "source": [
    "We will use `medmnist`, a python library that contains multiple medical imaging datasets for experimentation. You can install it locally via `pip install medmnist` or in google colab with `!pip install medmnist`\n",
    "\n",
    "### The story\n",
    "\n",
    "We found some pretrained resnet models on large-scale natural image data and we want to see if the learned weights are usefull for our medical image classification.\n",
    "\n",
    "- Task 1 and 2: To this end, we will first evaluate the [K-nearest neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) (KNN) accuracy, using features from a pretrained resnet. We will compare the representations of resnet18 and resnet50\n",
    "- Task 3: Next, we will use the features as training data, instead of the images, and train an MLP on top.\n",
    "- Task 4: We will try to avoid overfitting by applying regularization techniques.\n",
    "- Task 5: Finally, we will train the whole network (resnet50), starting from pretrained imagenet weights.\n",
    "\n",
    "Our new goal is to reach a 95% val. accuracy on pathmnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6SP-NCj3SP6",
    "outputId": "42c71a15-44b6-4121-b6eb-48cd12be1e83"
   },
   "outputs": [],
   "source": [
    "!pip install medmnist\n",
    "!wget -c https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPl8_2axorg6",
    "outputId": "3621764b-81ef-44fb-cd26-d225e89382a5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import medmnist\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from medmnist import INFO\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Warning: local import - utils.py must be in the same folder as this notebook\n",
    "from utils import *\n",
    "\n",
    "# Specify dataset\n",
    "data_flag = 'pathmnist'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "download = True\n",
    "batch_size = 256\n",
    "info = INFO[data_flag]\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "print(\"n_classes\", n_classes, info)\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "os.makedirs(\"./figs/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "TvrS7jszV7to",
    "outputId": "8239e91e-e986-4e80-dfed-969a7a73e8be"
   },
   "outputs": [],
   "source": [
    "# Moves the range [0,1] to [-1,1]\n",
    "mean = torch.tensor([0.5], dtype=torch.float32)\n",
    "std = torch.tensor([0.5], dtype=torch.float32)\n",
    "\n",
    "plain_transform = T.Compose([T.ToTensor(), T.Normalize(list(mean), list(std))])\n",
    "\n",
    "# load the data\n",
    "train_ds_plain = DataClass(split='train', transform=plain_transform, download=download)\n",
    "val_ds = DataClass(split='val', transform=plain_transform, download=download)\n",
    "test_ds = DataClass(split='test', transform=plain_transform, download=download)\n",
    "\n",
    "train_loader_plain1 = data.DataLoader(dataset=train_ds_plain, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "img1, lab = next(iter(train_loader_plain1))\n",
    "\n",
    "# show the images\n",
    "plt.figure(figsize = (50,20))\n",
    "for i in range(10):\n",
    "    imshow(train_ds_plain[i][0], i, mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoDj5JShEA5G"
   },
   "source": [
    "\n",
    "# Task 1\n",
    "\n",
    "Implement the logic of using a pretrained model to produce embeddings and apply KNN on top.\n",
    "More precisly, given a pretrained model and a train and test loader, it computes the embeddings (on the gpu) and then uses the class `sklearn.neighbors.KNeighborsClassifier` to create a classifier. The classifier is created from the train embeddings and computes the train and test accuracy for both data splits.\n",
    "\n",
    "### Optional - encapsulate the logic in a class\n",
    "You can encapsulate the aforementioned logic by filling up the methods in the class below.\n",
    "Minimal documentation is provided for each class method.\n",
    "The method `execute` illustrates how the class methods should be used.\n",
    "\n",
    "```python\n",
    "class KnnConvnet():\n",
    "    def __init__(self, model, device='cpu', distance='cosine'):\n",
    "        super(KnnConvnet, self).__init__()\n",
    "    def get_features(self, mode='train'):\n",
    "    def set_features(self, embeds, labels, mode='train'):\n",
    "    def extract_features(self, loader):\n",
    "    def fit(self, features, labels, k):\n",
    "    def accuracy(self, features, labels):\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def execute(self, train_loader, test_loader=None, k=1):\n",
    "        if self.embeds_train is None:\n",
    "            embeds_train, lab_train = self.extract_features(train_loader)\n",
    "            self.set_features(embeds_train, lab_train, mode='train')\n",
    "        \n",
    "        self.fit(self.embeds_train, self.lab_train, k)\n",
    "        train_acc = self.accuracy(self.embeds_train, self.lab_train)\n",
    "\n",
    "        if test_loader is not None:\n",
    "            if self.embeds_test is None:\n",
    "                embeds_test, lab_test = self.extract_features(test_loader)\n",
    "                self.set_features(embeds_test, lab_test, mode='test')\n",
    "            \n",
    "            test_acc = self.accuracy(self.embeds_test, self.lab_test)\n",
    "            return train_acc, test_acc\n",
    "        \n",
    "        return train_acc\n",
    "```\n",
    "\n",
    "\n",
    "#### Tips\n",
    "\n",
    "- Feature extraction is much much faster on the GPU\n",
    "- Use the cosine similarity as a distance metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHe1p1vhD-hq",
    "outputId": "9d43439a-b6cf-441d-e0c1-f3f3c493d240"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from torch import nn\n",
    "\n",
    "class KnnConvnet():\n",
    "    def __init__(self, model, device='cpu', distance='cosine'):\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.model.eval()\n",
    "        self.embeds_train = None\n",
    "        self.lab_train = None\n",
    "        self.lab_test = None\n",
    "        self.embeds_test = None\n",
    "        self.distance = distance\n",
    "\n",
    "    def get_features(self, mode='train'):\n",
    "        \"\"\"Returns the embeddings of the train or test set.\n",
    "        Args:\n",
    "            mode (str, optional): \"train\" or \"test\". Defaults to 'train'.\n",
    "        \"\"\"\n",
    "        assert self.embeds_train is not None, 'Training embedding are not computed yet.'\n",
    "        assert self.embeds_test is not None, 'Test embedding are not computed yet.'\n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def set_features(self, embeds, labels, mode='train'):\n",
    "        \"\"\"Sets the train or test embeddings and their labels.\"\"\"\n",
    "        ### START CODE HERE ### (approx. 6 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def extract_features(self, loader):\n",
    "        \"\"\"Infers features from the provided image loader.\n",
    "        Args:\n",
    "            loader: train or test loader\n",
    "        Returns: 3 tensors of all: features, labels\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        label_lst = []\n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        ### END CODE HERE ###\n",
    "        h_total = torch.cat(features)\n",
    "        label_total = torch.cat(label_lst)\n",
    "        return h_total, label_total\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fit(self, features, labels, k):\n",
    "        \"\"\"Fits the provided features to create a KNN classifer (i.e. self.cls object).\n",
    "        Args:\n",
    "            features: [... , dataset_size, feat_dim]\n",
    "            labels: [... , dataset_size]\n",
    "            k: number of nearest neighbours for majority voting\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "\n",
    "    def accuracy(self, features, labels):\n",
    "        \"\"\"Uses the features to compute the accuracy of the classifier (i.e. self.cls object).\"\"\"\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        ### END CODE HERE ###\n",
    "        return acc\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def execute(self, train_loader, test_loader=None, k=10):\n",
    "        if self.embeds_train is None:\n",
    "            embeds_train, lab_train = self.extract_features(train_loader)\n",
    "            self.set_features(embeds_train, lab_train, mode='train')\n",
    "\n",
    "        self.fit(self.embeds_train, self.lab_train, k)\n",
    "        train_acc = self.accuracy(self.embeds_train, self.lab_train)\n",
    "\n",
    "        if test_loader is not None:\n",
    "            if self.embeds_test is None:\n",
    "                embeds_test, lab_test = self.extract_features(test_loader)\n",
    "                self.set_features(embeds_test, lab_test, mode='test')\n",
    "\n",
    "            test_acc = self.accuracy(self.embeds_test, self.lab_test)\n",
    "            return train_acc, test_acc\n",
    "\n",
    "        return train_acc\n",
    "\n",
    "def test_knn():\n",
    "    d1 = torch.utils.data.Subset(train_ds_plain, list(range(300)))\n",
    "    d2 = torch.utils.data.Subset(val_ds, list(range(100)))\n",
    "    train_loader = data.DataLoader(dataset=d1, batch_size=32, shuffle=False, drop_last=False)\n",
    "    test_loader = data.DataLoader(dataset=d2, batch_size=32, shuffle=False, drop_last=False)\n",
    "    model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "    knn_cls = KnnConvnet(model, device=device)\n",
    "    for k in 1, 5:\n",
    "        train_acc, test_acc = knn_cls.execute(train_loader, test_loader, k=k)\n",
    "        print(f\"train acc: {train_acc:.2f}%, test acc: {test_acc:.2f}%\")\n",
    "\n",
    "test_knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz4_pSeE3SP9"
   },
   "source": [
    "# Expected results\n",
    "\n",
    "```\n",
    "train acc: 100.00%, test acc: 48.00%\n",
    "train acc: 74.67%, test acc: 56.00%\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh0G8E-A3SP9"
   },
   "source": [
    "# Task 2: Use the KNN classifier on pretrained features of resnet50\n",
    "\n",
    "Now we will use the KNN class together with two models: resnet50 and resnet18. These are out-of-the-box models, available in the `torchvision` package.  \n",
    "\n",
    "- Load the resnet18 and resnet50 models from `torchvision`, pretrained on the imagenet dataset.\n",
    "- Remove the last layer (use print(model) to see what it's called).\n",
    "- Compute the image embeddings for all training and test data, using the `extract_features` function. These now serve as our new, transformed data. We will use the validation dataloader as test data.\n",
    "- When computing the training accuracy, use a random subset of 10000 elements of the training data (otherwise it can be quite slow)\n",
    "- Find the best choice of K in KNN (hyperparameter search). Try at least 4 different values of K for both models.\n",
    "- Plot the results in a scatter plot for both resnet18 and resnet50.\n",
    "- **Important: save the image embeddings** from resnet50 for the next task (i.e. with `torch.save`).\n",
    "\n",
    "PS: Use the non-augmented train and validation dataloaders.\n",
    "\n",
    "You are expected to observe at least 72% val accuracy with resnet50.\n",
    "\n",
    "Hint: those working with google colab you can download files with:\n",
    "\n",
    "```python\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "# saves file to local google colab enviroment\n",
    "result.to_csv('example_file.csv')\n",
    "# downloads it to your computer\n",
    "files.download('example_file.csv')\n",
    "```\n",
    "It works with any type of file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKt8s_C33SP-",
    "outputId": "01059557-692e-4139-cade-39ebab1acbb3"
   },
   "outputs": [],
   "source": [
    "def get_model(modelname=\"resnet18\", pretrained=True):\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    ### END CODE HERE ###\n",
    "    return model\n",
    "\n",
    "def run_knn_hp_tuning(model, train_loader, test_loader,\n",
    "                        range_k = [5, 10, 15, 20], device='cpu', modelname='resnet'):\n",
    "    train_acc_all = []\n",
    "    val_acc_all = []\n",
    "    knn_cls = KnnConvnet(model, device)\n",
    "\n",
    "    print(\"Calc. train features\")\n",
    "    ### START CODE HERE ### (approx. 4 lines)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    print(\"Calc. test features\")\n",
    "    ### START CODE HERE ### (approx. 4 lines)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    for k in range_k:\n",
    "        ### START CODE HERE ### (approx. 3 lines)\n",
    "        ### END CODE HERE ###\n",
    "    return train_acc_all, val_acc_all\n",
    "\n",
    "train_loader_plain2 = data.DataLoader(dataset=train_ds_plain, batch_size=1024, shuffle=True, drop_last=False)\n",
    "val_loader = data.DataLoader(dataset=val_ds, batch_size=1024, shuffle=False, drop_last=False)\n",
    "\n",
    "backbone_r18 = get_model(\"resnet18\")\n",
    "backbone_r50 = get_model(\"resnet50\")\n",
    "\n",
    "range_k = [5, 10, 15, 20]\n",
    "train_acc_r18, val_acc_r18 = run_knn_hp_tuning(backbone_r18, train_loader_plain2,\n",
    "    val_loader, range_k, device, modelname=\"resnet18\")\n",
    "\n",
    "train_acc_r50, val_acc_r50 = run_knn_hp_tuning(backbone_r50, train_loader_plain2,\n",
    "    val_loader, range_k, device, modelname=\"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "SV_pQsTU3SP_",
    "outputId": "44e8115a-4594-4075-d0d4-b3e4467b15d9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_knn_accs(range_k, train_acc_all, val_acc_all,  modelname='resnet18'):\n",
    "    plt.plot(range_k, train_acc_all, marker='o', label=f'{modelname} train acc %')\n",
    "    plt.plot(range_k , val_acc_all, marker='x', label=f\"{modelname} val. acc %\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_knn_accs(range_k, train_acc_r18, val_acc_r18,  modelname='resnet18')\n",
    "plot_knn_accs(range_k, train_acc_r50, val_acc_r50,  modelname='resnet50')\n",
    "plt.legend( bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.xticks([]) # hides x axis\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(f\"Accuracy %\")\n",
    "plt.title(\"Benchmarking resnet18 and resnet50 embeddings with KNN\")\n",
    "plt.savefig(\"./figs/knn_accs_resnets.png\", dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TJfxy6y3SP_"
   },
   "source": [
    "### Expected result\n",
    "\n",
    "![im1](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_accs_resnets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhGpKJZ4Zpwn"
   },
   "source": [
    "# Task 3: Train an MLP on the extracted image features from resnet50\n",
    "\n",
    "- Create new datasets and dataloaders that return a pair of (features, labels) from resnet50 instead of the image.\n",
    "\n",
    "Since we have precomputed the features, you can use `torch.load` here to load the features and labels and `torch.utils.data.TensorDataset` to make a dataset.\n",
    "\n",
    "- Train a 2-layer MLP with a ReLU activation on the extracted features from the pretrained resnet50 as input data.\n",
    "- Train for at least 100 epochs with Adam.\n",
    "- Expected val accuracy is 84%\n",
    "\n",
    "Hint: For small models, just nn.Sequential produces a fully functioning model. You don't need to define an extra class here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "exAI0NGFZpHS",
    "outputId": "5192fa43-d023-400b-dffc-2867393cf8f3"
   },
   "outputs": [],
   "source": [
    "# load embeds from hard disk\n",
    "### START CODE HERE ### (approx. 2 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# create dataset\n",
    "### START CODE HERE ### (approx. 2 lines)\n",
    "### END CODE HERE ###\n",
    "print(\"Feature datasets have been created\")\n",
    "\n",
    "# create dataloaders\n",
    "### START CODE HERE ### (approx. 2 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# create model\n",
    "### START CODE HERE ### (approx. 1 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "num_epochs = 100\n",
    "# setup optimizer\n",
    "### START CODE HERE ### (approx. 1 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "dict_log = train(model, optimizer, num_epochs, train_loader_features, val_loader_features, device)\n",
    "\n",
    "figsize = (15,10)\n",
    "plt.figure(figsize=figsize)\n",
    "plot_stats(dict_log, baseline=84, modelname=\"MLP/Resnet50\")\n",
    "plt.savefig(fname=\"./figs/mlp_resnet50_embeds.png\", dpi=500, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Best val. acc\", np.max(dict_log[\"val_acc_epoch\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5pmFZGS3SQA"
   },
   "source": [
    "\n",
    "### Expected result\n",
    "\n",
    "![im2](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/mlp_resnet50_embeds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4_2kgl33SQA"
   },
   "source": [
    "# Task 4: Regularization strategies\n",
    "If you trained the model, you should be able to see the overfitting behaviour with a degradation in loss/accuracy towards the end of training.\n",
    "\n",
    "What regularization strategies could you use to prevent the model from overfitting?\n",
    "\n",
    "Experiment with at least 1 regularization strategy (apart from tuning the weight decay) and see if you can further increase the performance.\n",
    "\n",
    "- Does regularization lead to performance improvement?\n",
    "- How do the training dynamics change when training with stronger regularization strategies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfHB8Ep-3SQA"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 3 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "dict_log = train(model, optimizer, num_epochs, train_loader_features, val_loader_features, device)\n",
    "\n",
    "figsize = (15,10)\n",
    "plt.figure(figsize=figsize)\n",
    "plot_stats(dict_log, baseline=84, modelname=\"MLP/Resnet50\")\n",
    "plt.savefig(fname=\"./figs/mlp_resnet50_embeds_regularization.png\", dpi=500, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Best val. acc\", np.max(dict_log[\"val_acc_epoch\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SLAG1kq3SQA"
   },
   "source": [
    "### Expected result\n",
    "\n",
    "![im3](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/mlp_resnet50_embeds_regularization.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z-7i7Z4FNxR"
   },
   "source": [
    "# Task 5: Train the whole model (resnet50) on pathmnist starting from imagenet initialization.\n",
    "\n",
    "Now we will re-train the whole model, using the pretrained weights as a starting point. Also, we add data-augmentation, see below for details.\n",
    "\n",
    "Training data augmentations:\n",
    "- Horizontal flip with 50% probability\n",
    "- Random crop images to 50-100 % of the initial size\n",
    "- Resize images to 28x28\n",
    "- intensity jitter: 20% brightness and 20% contrast with 80% probability\n",
    "- Mean/std norm with mean=0.5 and std=0.5 for all channels\n",
    "\n",
    "At val/test time, only mean/std normalization will be applied.\n",
    "\n",
    "\n",
    "Do the following:\n",
    "- Load a pretrained resnet50. Remove the pretrained head (last layer). Add a two-layer MLP as the new last layer.\n",
    "- Compute the number of trainable and non-trainable parameters.\n",
    "- Train for 20 epochs.\n",
    "- Plot training statistics\n",
    "- Calculate test accuracy!\n",
    "\n",
    "\n",
    "Compare the fine-tuned resnet50 on the pathmnist dataset with the previously trained MLP on the extracted features.\n",
    "\n",
    "Expected val. acc is 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3IBG8V6FMr5"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 9 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# For val/time define a plain transform\n",
    "plain_transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(list(mean), list(std))])\n",
    "\n",
    "# load the data\n",
    "train_ds = DataClass(split='train', transform=train_transform, download=download)\n",
    "\n",
    "train_loader = data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8, pin_memory=True, persistent_workers=True)\n",
    "val_loader = data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "test_loader = data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "# create model\n",
    "class ResnetMedNist(nn.Module):\n",
    "    def __init__(self, hidden_mlp, n_classes):\n",
    "        super(ResnetMedNist, self).__init__()\n",
    "        ### START CODE HERE ### (approx. 3 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (approx. 1 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "\n",
    "# Initialize model and optimizer\n",
    "num_epochs = 20\n",
    "### START CODE HERE ### (approx. 2 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "# Number of parameters\n",
    "### START CODE HERE ### (approx. 2 lines)\n",
    "### END CODE HERE ###\n",
    "print(f\" Total params: {pytorch_total_params:.1f} M , trainble params {pytorch_total_params_trainable:.1f}\")\n",
    "\n",
    "dict_log = train(model, optimizer, num_epochs, train_loader, val_loader, device)\n",
    "\n",
    "figsize = (15,10)\n",
    "plt.figure(figsize=figsize)\n",
    "plot_stats(dict_log, baseline=94, modelname=\"Resnet50 + MLP fine-tuning\")\n",
    "plt.savefig(fname=\"./figs/mlp_resnet50_finetune_embeds.png\", dpi=500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwx0yNok3SQB"
   },
   "source": [
    "## Expected results\n",
    "![im4](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/mlp_resnet50_finetune_embeds.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5-SB3XM3SQB"
   },
   "source": [
    "# Task 6: Visualizing the nearest neighbors in the embeddings space.\n",
    "\n",
    "- Load the embeddings (produced from resnet50) and their labels from the validation set.\n",
    "- Take 1 image sample from each class.\n",
    "- Calculate their top k=7 nearest neighbors (NN) using cosine similarity.\n",
    "- Visualize the 7+1 images in one row. First one should be the reference image that we computed its NN.\n",
    "\n",
    "PS: we use 7 so we can plot them in 1 row. Feel free to play around with more NN.\n",
    "\n",
    "#### Questions\n",
    "- What is the connections between the NN in the embedding space and the image labels?\n",
    "- How many of the retrieved images in the embedding space share the same label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NJDgkee3SQB"
   },
   "outputs": [],
   "source": [
    "plain_transform = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Resize(128),\n",
    "        T.Normalize(list(mean), list(std))])\n",
    "val_ds = DataClass(split='val', transform=plain_transform, download=download)\n",
    "\n",
    "### START CODE HERE ### (approx. 3 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Normalize the embeddings, so that a normal vector product is the cosine similarity\n",
    "### START CODE HERE ### (approx. 1 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "ref_imgs = []  # Save one image per class\n",
    "ref_ids = []  # Save the indices for these images\n",
    "for j in range(n_classes):\n",
    "    ### START CODE HERE ### (approx. 3 lines)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "ref_imgs = torch.stack(ref_imgs)\n",
    "\n",
    "# For each image, compute the k nearest neighbours, according to cosine similarity\n",
    "### START CODE HERE ### (approx. 3 lines)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Visualize the reference image and its 7 nearest neighbors\n",
    "for c, ref in enumerate(ref_ids):\n",
    "    knns = indices[c]\n",
    "    imgs_to_viz = [val_ds[ref][0]]\n",
    "    true_labels = [val_ds[ref][1]]\n",
    "    for i in knns:\n",
    "        imgs_to_viz.append(val_ds[i][0])\n",
    "        true_labels.append(val_ds[i][1])\n",
    "    # show the images\n",
    "    plt.figure(figsize = (22,14))\n",
    "    for j in range(k+1):\n",
    "        label = int(true_labels[j])\n",
    "        imshow(imgs_to_viz[j], j, mean, std)\n",
    "        plt.title(f\"Label {label}\", fontsize = 14)\n",
    "    plt.savefig(f'./figs/knn_from_ref_label_id_{str(c).zfill(2)}',bbox_inches = \"tight\", dpi = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr4-ug4z3SQB"
   },
   "source": [
    "### Expected results\n",
    "\n",
    "![im6](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_00.png)\n",
    "\n",
    "![im7](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_01.png)\n",
    "\n",
    "![im8](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_02.png)\n",
    "\n",
    "![im9](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_03.png)\n",
    "\n",
    "![im10](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_04.png)\n",
    "\n",
    "![im11](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_05.png)\n",
    "\n",
    "![im12](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_06.png)\n",
    "\n",
    "![im13](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_07.png)\n",
    "\n",
    "![im14](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a09_transfer_learning/figs/knn_from_ref_label_id_08.png)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc5fcf396fe0abd4fa852aee332a0572494dcaf5776820055c87d9b84157f362"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
