{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APoZE2Q-i3l7"
      },
      "source": [
        "# General\n",
        "\n",
        "In this exercise we will train various small MLPs on predicting IQ from a few other characteristics.\n",
        "We will explore the concepts of\n",
        "- mini-batch training and\n",
        "- training/validation/test split of the data.\n",
        "\n",
        "You will have to fill in the gaps in the code, run the experiments and prepare results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPmkUK1mi3l9"
      },
      "source": [
        "## Mini-Batch Training\n",
        "\n",
        "First, here is the idea behind mini-batch training:\n",
        "For larger datasets it is computationally disadvantageous to compute gradients for all training examples and then make a full gradient descent step. Instead, we subsample a mini-batch, i.e. a subset of training examples. For them, we compute the forward and backward pass and make a gradient step. One pass through all examples in the training set is called an epoch.\n",
        "\n",
        "In pseudo-code, we do the following:\n",
        "\n",
        "- For epoch=1,...\n",
        "    - Choose minibatches mb_1,...,mb_k that cover the full training set\n",
        "    - For each minibath mb = {(x'_1,y'_1),...,(x'_l,y'_l)}\n",
        "        - Compute gradients of loss for each element (x'_i, y'_i) w.r.t. each trainable parameter\n",
        "        - Make update step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d2e8ao6i3l-"
      },
      "source": [
        "## Data Split\n",
        "\n",
        "In order to assess generalization error, we split the dataset into a\n",
        "- training subset (typically ~70 - 80%) that we train on\n",
        "- a validation subset (typically ~10 - 20%) that we use choose best hyperarameters and pick the right number of training iterations for early stopping\n",
        "- a test subset (typically ~10%) to estimate generalization error.\n",
        "\n",
        "**Important**: Never use the test set to tune your model! It cannot influence model selection or training in any way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY_0Fo3Hi3l-"
      },
      "source": [
        "First, let us import the needed libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I4coZg3Ei3l-"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN7Xn4hOi3l_"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "LA3ALCWSi3l_",
        "outputId": "c909762a-c277-4000-804b-ae800b8e63fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   obs    gpa   iq  gender  concept\n",
              "0    1  7.940  111       2       67\n",
              "1    2  8.292  107       2       43\n",
              "2    3  4.643  100       2       52\n",
              "3    4  7.470  107       2       66\n",
              "4    5  8.882  114       1       58"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44ea07c4-b745-4655-b22c-2aee56dd3633\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>obs</th>\n",
              "      <th>gpa</th>\n",
              "      <th>iq</th>\n",
              "      <th>gender</th>\n",
              "      <th>concept</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7.940</td>\n",
              "      <td>111</td>\n",
              "      <td>2</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>8.292</td>\n",
              "      <td>107</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.643</td>\n",
              "      <td>100</td>\n",
              "      <td>2</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7.470</td>\n",
              "      <td>107</td>\n",
              "      <td>2</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>8.882</td>\n",
              "      <td>114</td>\n",
              "      <td>1</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44ea07c4-b745-4655-b22c-2aee56dd3633')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44ea07c4-b745-4655-b22c-2aee56dd3633 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44ea07c4-b745-4655-b22c-2aee56dd3633');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-76a3b8c4-1b48-41f7-a45b-0f44eed06976\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-76a3b8c4-1b48-41f7-a45b-0f44eed06976')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-76a3b8c4-1b48-41f7-a45b-0f44eed06976 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 78,\n  \"fields\": [\n    {\n      \"column\": \"obs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 1,\n        \"max\": 89,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          36,\n          1,\n          37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gpa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0995574406415862,\n        \"min\": 0.53,\n        \"max\": 10.76,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          9.999,\n          7.598,\n          8.882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"iq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 72,\n        \"max\": 136,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          79,\n          98,\n          115\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concept\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 20,\n        \"max\": 80,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          37,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = pd.read_csv(\"gpa_iq.csv\")\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BycTwoX0i3l_"
      },
      "source": [
        "Value class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Toq8AijWi3l_"
      },
      "outputs": [],
      "source": [
        "class Value:\n",
        "    \"\"\"\n",
        "    Added `exp` and `pow`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, _children=(), operation=\"\", label=\"\"):\n",
        "        self.data = data\n",
        "        self._prev = set(_children)\n",
        "        self._operation = operation\n",
        "        self._label = label\n",
        "\n",
        "        # because we assume that the value doesn't affect the\n",
        "        # loss function by default, thus the slope is 0.0\n",
        "        self.grad = 0.0\n",
        "\n",
        "        # This will store a function which will calculate the\n",
        "        # local derivative according to the operation and store\n",
        "        # in the `self.grad` variable.\n",
        "        self._backward = lambda : None\n",
        "\n",
        "    def tanh(self):\n",
        "        x = self.data\n",
        "        t = (np.exp(2*x) - 1) / (np.exp(2*x) + 1)\n",
        "        out = Value(t, (self,), \"tanh\")\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += (1 - t ** 2) * out.grad # chain rule here too!\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def backward(self):\n",
        "        topo = []\n",
        "        visited = set()\n",
        "\n",
        "        def build_topo(v):\n",
        "            if v not in visited:\n",
        "                visited.add(v)\n",
        "                for child in v._prev:\n",
        "                    build_topo(child)\n",
        "                topo.append(v)\n",
        "        build_topo(self)\n",
        "\n",
        "        self.grad = 1.0\n",
        "        for node in reversed(topo):\n",
        "            node._backward()\n",
        "\n",
        "\n",
        "    def __add__(self, other):\n",
        "        other = Value(other) if not isinstance(other, Value) else other\n",
        "        out = Value(self.data + other.data, (self, other), '+')\n",
        "        def _backward():\n",
        "            self.grad += 1.0 * out.grad\n",
        "            other.grad += 1.0 * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "\n",
        "    def __truediv__(self, other):\n",
        "        other = Value(other) if not isinstance(other, Value) else other\n",
        "        out =  Value(self.data / other.data, (self, other), '/')\n",
        "        def _backward():\n",
        "            self.grad += (1.0 / other.data) * out.grad\n",
        "            other.grad += self.data * (-1.0 / other.data**2) * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        other = Value(other) if not isinstance(other, Value) else other\n",
        "        out = Value(self.data * other.data, (self, other), '*')\n",
        "        def _backward():\n",
        "            self.grad += other.data * out.grad\n",
        "            other.grad += self.data * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        other = Value(other) if not isinstance(other, Value) else other\n",
        "        out = Value(self.data - other.data, (self, other), '-')\n",
        "        def _backward():\n",
        "            self.grad += 1.0 * out.grad\n",
        "            other.grad += -1.0 * out.grad\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def __radd__(self, other):\n",
        "        return self + other\n",
        "\n",
        "    def __rmul__(self, other):\n",
        "        return self * other\n",
        "\n",
        "    def __rsub__(self, other):\n",
        "        return self - other\n",
        "\n",
        "    def __rtruediv__(self, other):\n",
        "        return self / other\n",
        "\n",
        "    def __pow__(self, other):\n",
        "        assert isinstance(other, (int, float)), \"Only int/float can be used\"\n",
        "        out = Value(self.data ** other, (self, ), f'**{other}')\n",
        "\n",
        "        def _backward():\n",
        "            self.grad += other * (self.data ** (other - 1)) * out.grad # chain rule\n",
        "        out._backward = _backward\n",
        "        return out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Value(data={self.data})\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hod73Hapi3mA"
      },
      "source": [
        "Neuron class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KS8fdrRNi3mA"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    \"\"\"\n",
        "    Making a new function `parameters` which will return ONLY the weights + bias.\n",
        "    \"\"\"\n",
        "    def __init__(self, nin, activate=True):\n",
        "        self.w = [Value(np.random.uniform(-1, 1), label=f'w{i}') for i in range(nin)]\n",
        "        self.b = Value(np.random.uniform(-1, 1), label='b')\n",
        "        self.activate = activate\n",
        "\n",
        "    def __call__(self, x):\n",
        "        assert len(x) == len(self.w)\n",
        "        out = sum(xi*wi for xi, wi in zip(x, self.w)) + self.b\n",
        "        if self.activate:\n",
        "            out = out.tanh()\n",
        "        return out\n",
        "\n",
        "    def parameters(self):\n",
        "        return self.w + [self.b]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtiYeFZYi3mA"
      },
      "source": [
        "Layer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0UoVQsumi3mA"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    \"\"\"\n",
        "    Added a new function `parameters` which will fetch all params from all neurons\n",
        "    and then make a flat list of all params\n",
        "    \"\"\"\n",
        "    def __init__(self, nin, nout, activated=True):\n",
        "        self.neurons = [Neuron(nin,activated) for _ in range(nout)]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        activateds = [n(x) for n in self.neurons]\n",
        "        return activateds[0] if len(activateds) == 1 else activateds\n",
        "\n",
        "    def parameters(self):\n",
        "        params = [] # the flat list of params\n",
        "        for neuron in self.neurons:\n",
        "            ps = neuron.parameters()\n",
        "            params.extend(ps)\n",
        "        return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad0VQS9-i3mB"
      },
      "source": [
        "MLP class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "odYt6hiWi3mB"
      },
      "outputs": [],
      "source": [
        "class MLP:\n",
        "    \"\"\"\n",
        "    Added a new function `parameters` to get the parameters from all layers and\n",
        "    then flatten it.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nin: int, nouts: List):\n",
        "        sizes = [nin] + nouts\n",
        "        self.layers = []\n",
        "\n",
        "        for i in range(len(nouts)):\n",
        "            activated = True if i != len(nouts) - 1 else False\n",
        "            layer = Layer(sizes[i], sizes[i + 1], activated)\n",
        "            self.layers.append(layer)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def parameters(self):\n",
        "        params = [] # the flat list of params\n",
        "        for layer in self.layers:\n",
        "            ps = layer.parameters()\n",
        "            params.extend(ps)\n",
        "        return params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjkA1WdJi3mB"
      },
      "source": [
        "Training - mini batch + train/val/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KDudMEigi3mB",
        "outputId": "9b94b8a7-8578-4b30-adae-52ea09b05614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported format string passed to Value.__format__",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b4c715f65b7c>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Evaluate on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Value.__format__"
          ]
        }
      ],
      "source": [
        "# Extract features and target\n",
        "X = data[['gpa', 'gender', 'concept']].values\n",
        "y = data['iq'].values.astype(float)\n",
        "\n",
        "# normalize features and target\n",
        "X /= X.max(axis=0)\n",
        "y /= 100.0\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "np.random.seed(42)  # For numpy operations if needed\n",
        "\n",
        "# Generate shuffled indices\n",
        "indices = list(range(len(X)))\n",
        "random.shuffle(indices)\n",
        "\n",
        "# Split the indices into 80% train, 10% validation, 10% test in order provided by indices.\n",
        "X_train, y_train = X[indices[:int(np.floor(0.8*len(indices)))],:], y[indices[:int(np.floor(0.8*len(indices)))]] # To be filled\n",
        "X_val, y_val = X[indices[int(np.floor(0.8*len(indices)))+1:int(np.floor(0.9*len(indices)))],:], y[indices[int(np.floor(0.8*len(indices)))+1:int(np.floor(0.9*len(indices)))]] # To be filled\n",
        "X_test, y_test = X[indices[int(np.floor(0.9*len(indices)))+1:len(indices)],:], y[indices[int(np.floor(0.9*len(indices)))+1:len(indices)]] # To be filled\n",
        "\n",
        "# Define the model\n",
        "model = MLP(3, [4, 2, 1]) # to be filled. Try different architectures up to three hidden layers.\n",
        "\n",
        "# Get the parameters\n",
        "parameters = model.parameters()\n",
        "\n",
        "# Hyperparameters\n",
        "lr = 0.05  # To be filled. Try different learning rates.\n",
        "num_epochs = 100  # To be filled. Try different number of epochs.\n",
        "batch_size = 8\n",
        "\n",
        "# Lists to store losses for plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "num_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx in range(num_batches):\n",
        "      if batch_idx < num_batches -1:\n",
        "        #forward pass for each training batch\n",
        "        preds = [model(x) for x in X_train[batch_idx*batch_size:(batch_idx+1)*batch_size]]\n",
        "        #calculate the loss for each training batch\n",
        "        loss = [(ytrue - ypred)**2 for ytrue, ypred in zip(y_train[batch_idx*batch_size:(batch_idx+1)*batch_size], preds)]\n",
        "        loss = sum(loss)\n",
        "        total_loss += loss\n",
        "        #backward pass for each training batch\n",
        "        loss.backward()\n",
        "        #update the weights and biases after each batch\n",
        "        for p in model.parameters():\n",
        "          p.data += -lr * p.grad\n",
        "      #forward pass for the last batch\n",
        "      preds = [model(x) for x in X_train[(num_batches-1)*batch_size:]]\n",
        "      #calculate the loss for the last batch\n",
        "      loss = [(ytrue - ypred)**2 for ytrue, ypred in zip(y_train[(num_batches-1)*batch_size:], preds)]\n",
        "      loss = sum(loss)\n",
        "      total_loss += loss\n",
        "      #backward pass for the last batch\n",
        "      loss.backward()\n",
        "      #update the weights and biases after the last batch\n",
        "      for p in model.parameters():\n",
        "        p.data += -lr * p.grad\n",
        "      # Here the lacking code should be included...\n",
        "    avg_loss = total_loss / len(X_train)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_loss = 0.0\n",
        "    for x_i, y_i in zip(X_val, y_val):\n",
        "        x_values = [Value(x) for x in x_i]\n",
        "        y_pred = model(x_values)\n",
        "        loss = (y_pred - Value(y_i)) ** 2\n",
        "        val_loss += loss.data\n",
        "\n",
        "    avg_val_loss = val_loss / len(X_val)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "# Plot the training and validation loss over epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# After training, evaluate on the test set using MLP\n",
        "mlp_test_loss = 0.0\n",
        "for x_i, y_i in zip(X_test, y_test):\n",
        "    x_values = [Value(x) for x in x_i]\n",
        "    y_pred = model(x_i)\n",
        "    loss = (y_pred - y_i) ** 2\n",
        "    mlp_test_loss += loss.data\n",
        "\n",
        "avg_mlp_test_loss = mlp_test_loss / len(X_test)\n",
        "print(f\"MLP Test Loss (MSE): {avg_mlp_test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0V_4C2xi3mC"
      },
      "source": [
        "Compare the results with linear regression by evaluating how your MLP predictions align with those generated by a simple Linear Regression model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEZzldSKi3mC"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------------------\n",
        "# Linear Regression Comparison\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# Add a column of ones to X_train and X_test for the intercept term\n",
        "ones_train = np.ones((X_train.shape[0], 1))\n",
        "X_train_lr = np.hstack((X_train, ones_train))\n",
        "\n",
        "ones_test = np.ones((X_test.shape[0], 1))\n",
        "X_test_lr = np.hstack((X_test, ones_test))\n",
        "\n",
        "# Compute theta using the closed-form solution on the training set\n",
        "XT_X = np.matmul(X_train_lr.T, X_train_lr)\n",
        "XT_X_inv = np.linalg.inv(XT_X)\n",
        "XT_y = np.matmul(X_train_lr.T, y_train)\n",
        "theta = np.matmul(XT_X_inv, XT_y)\n",
        "\n",
        "print(\"\\nLinear Regression Coefficients (theta):\")\n",
        "print(theta)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_lr = np.matmul(X_test_lr, theta)\n",
        "\n",
        "# Compute Mean Squared Error for Linear Regression on the test set\n",
        "mse_lr = np.mean((y_pred_lr - y_test) ** 2)\n",
        "print(f\"Linear Regression Test Loss (MSE): {mse_lr:.4f}\")\n",
        "\n",
        "# Compare with MLP Test Loss\n",
        "print(\"\\nComparison of Test Losses:\")\n",
        "print(f\"MLP Test Loss (MSE): {avg_mlp_test_loss:.4f}\")\n",
        "print(f\"Linear Regression Test Loss (MSE): {mse_lr:.4f}\")\n",
        "\n",
        "labels = ['MLP', 'Linear Regression']\n",
        "test_losses = [avg_mlp_test_loss, mse_lr]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.bar(labels, test_losses, color=['blue', 'orange'])\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.title('Comparison of Test Losses')\n",
        "for i, v in enumerate(test_losses):\n",
        "    plt.text(i, v + 0.01 * max(test_losses), f\"{v:.4f}\", ha='center', fontweight='bold')\n",
        "plt.ylim(0, max(test_losses) * 1.1)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}