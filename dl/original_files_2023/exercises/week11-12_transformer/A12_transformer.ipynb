{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_VwCkXP7g2E"
   },
   "source": [
    "HHU Deep Learning, WS2023/24, 12.01.2023\n",
    "\n",
    "Lecture: Prof. Dr. Markus Kollmann\n",
    "\n",
    "Exercises: Nikolas Adaloglou, Felix Michels\n",
    "\n",
    "# Assignment 12 - IMDB Transformer Tutorial\n",
    "\n",
    "---\n",
    "\n",
    "Submit the solved notebook (not a zip) with your full name plus assignment number for the filename as an indicator, e.g `max_mustermann_a1.ipynb` for assignment 1. If we feel like you have genuinely tried to solve the exercise, you will receive 1 point for this assignment, regardless of the quality of your solution. This exercise is worth 2 points, since you have 2 weeks to complete it.\n",
    "\n",
    "## <center> DUE FRIDAY 26.01.2024 2:30 pm </center>\n",
    "\n",
    "Drop-off link: [https://uni-duesseldorf.sciebo.de/s/OMYOJSiTu2Fi8w8](https://uni-duesseldorf.sciebo.de/s/OMYOJSiTu2Fi8w8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVHwt6iS6rYP"
   },
   "source": [
    "# Part I. Preparation\n",
    "\n",
    "In this exercise you will be using the transformer architecture to do binary classification on the IMBD dataset.\n",
    "\n",
    "The dataset is available in the hugging face library called tranformer. You can install it via `!pip install datasets transformers`. You will only need to focus on the modeling part of the transformer architecture. To that end, you must **not** use any existing transformer module from any library. In the end, the goal of the exercise is to familiarize yourself with self-attention and the transformer architecture by implementing it yourself.\n",
    "\n",
    "For details on the architecture, have a look at the original [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "For excellent explanations of the individual parts, check out [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDtKT0Ht7oka",
    "outputId": "7829a0d3-c61d-43e7-a067-9a4e7e4fce60"
   },
   "outputs": [],
   "source": [
    "!pip install datasets transformers\n",
    "!wget -c https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a11-12_transformer/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "8e28231265924c1f892a466173385e0b",
      "8395d106009048a98c28f5f1df9dac01",
      "574ab8215cb14322b82e0aa410292c02",
      "2ec55e79b96c4a57b7d553ffc27d7fe2",
      "fb1869fb2ad44100a6731f94cac0ea5a",
      "73f6f54b84fd48be901c7803042fdf63",
      "8617475ba63d4b8c88cf8de88a5b3bef",
      "05167a303cd24530bbb0c95cadb46819",
      "89a0972611e341a598d846df26f91336",
      "d59af0304953408b9965ffc1202f7ee3",
      "3dc3b67c86f54d67b61aa369ede854a5"
     ]
    },
    "id": "N33v-bUvsBRP",
    "outputId": "6899bdfc-ce3e-4926-e7f5-6a906907b876"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Additional libraries that need to be installed in the environment\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import *\n",
    "\n",
    "raw_datasets = load_dataset(\"imdb\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# words of a movie to be the max seq length\n",
    "vocab_size = 50000\n",
    "maxlen = 5000 # max length of a sentence\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=300)\n",
    "\n",
    "def get_data_loader(batch_size=8, subset_of_data=None):\n",
    "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "    tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "    train_dataset = tokenized_datasets[\"train\"].shuffle()\n",
    "    val_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "    if subset_of_data is not None:\n",
    "        train_dataset = train_dataset.select(range(subset_of_data))\n",
    "        val_dataset = val_dataset.select(range(subset_of_data))\n",
    "\n",
    "    maxlen = len(train_dataset[0][\"input_ids\"])\n",
    "    train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "train_dataloader, val_dataloader = get_data_loader(batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTCe6baO7g2I",
    "outputId": "f12a0e5e-61f8-408f-918b-9edc9bed155c"
   },
   "outputs": [],
   "source": [
    "def test_data_loader():\n",
    "    batch = next(iter(train_dataloader))\n",
    "    print(batch.keys())\n",
    "    print(batch[\"input_ids\"].shape)\n",
    "    print(batch[\"input_ids\"][0,:])\n",
    "    print(batch[\"attention_mask\"].shape)\n",
    "    print(batch[\"attention_mask\"][0,:])\n",
    "    print(batch[\"labels\"].shape)\n",
    "test_data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CQpb86103Jz"
   },
   "source": [
    "# Part II. Implement PositionalEncoding\n",
    "\n",
    "**Task:** Implement the positional encoding as detailed in section 3.5 of the [paper](https://arxiv.org/abs/1706.03762)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEj0SJ2O7g2J"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model: int, embedding dimension\n",
    "            dropout: float, dropout rate\n",
    "            max_len: int, maximum length of the input sequence\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        ### END CODE HERE ###\n",
    "        self.pe = pe\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, max_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        ### END CODE HERE ###\n",
    "        return self.dropout(x)\n",
    "\n",
    "def test_PE():\n",
    "    \"\"\"\n",
    "    Test the positional encoding for shape errors\n",
    "    \"\"\"\n",
    "    pe = PositionalEncoding(d_model=32,max_len=500)\n",
    "    a = torch.rand(16,300,32)\n",
    "    assert (pe(a).shape == (16,300,32))\n",
    "\n",
    "test_PE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaXd4cwM7g2J"
   },
   "source": [
    "# Part II. Implement Global Average Pooling (GAP) and an MLP class\n",
    "\n",
    "These small components will be used later on for the transformer.\n",
    "\n",
    "**Task:** Implement the GAP class below. GAP is a layer that aggregates information, by taking the mean across a given dimension `dim`. Below, this will be the token representations from the output of the transformer.\n",
    "\n",
    "FYI: An alternative to this is to use a special class token, called CLS token in literature. It was first introduced in the BERT transformer. For this exercise, GAP suffices.\n",
    "\n",
    "**Task:** Implement the MLP class below. The MLP is called \"Position-wise Feed-Forward Networks\" in the paper, see section 3.3. Add a dropout layer at the end of the forward with probability `mlp_drop`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cP4Cxg-v7g2K"
   },
   "outputs": [],
   "source": [
    "class GlobalAveragePooling1D(nn.Module):\n",
    "    def __init__(self,dim=1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (approx. 1 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, actv_func=nn.ReLU, mlp_drop=0.):\n",
    "        super().__init__()\n",
    "        ### START CODE HERE ### (approx. 6 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "def test_MLP():\n",
    "    \"\"\"Test the MLP for shape errors\"\"\"\n",
    "    mlp = Mlp(in_features=32,hidden_features=64,out_features=32)\n",
    "    a = torch.rand(16,300,32)\n",
    "    assert (mlp(a).shape == (16,300,32))\n",
    "\n",
    "test_MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qdDxP7s7g2K"
   },
   "source": [
    "# Part III. Implement Multi-Head Self-Attention\n",
    "\n",
    "**Task:** Implement the Attention class below. See section 3.2.2 in the [paper](https://arxiv.org/abs/1706.03762) for details. Your class needs to support a variable number of heads and a variable embedding dimension (d_model). If you want, you can implement the class methods as we show below:\n",
    "\n",
    "```python\n",
    "def forward(self, x)\n",
    "    q, k, v = self.create_qkv(...)\n",
    "    attn = self.calc_attn(...)\n",
    "    x = self.calc_out(...)\n",
    "    return x, attn\n",
    "```\n",
    "\n",
    "There should be two dropout layers included here. One at the end of the `calc_attn` function with probability `attn_drop` and one at the end of the `calc_out` function with probability `proj_drop`.\n",
    "\n",
    "Avoid any kinds of loops here! Multi-head attention can be computed fully in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8lD_oWX7g2L"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=8, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        ### START CODE HERE ### (approx. 7 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def calc_attn(self, q, k):\n",
    "        ### START CODE HERE ### (approx. 3 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def calc_out(self, attn, v, B, N, C):\n",
    "        ### START CODE HERE ### (approx. 3 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def create_qkv(self,x, B, N, C):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (approx. 4 lines)\n",
    "        ### END CODE HERE ###\n",
    "        return x, attn\n",
    "\n",
    "\n",
    "def test_attention():\n",
    "    \"\"\"Test the Attention for shape errors\"\"\"\n",
    "    attn = Attention(d_model=32, num_heads=8)\n",
    "    a = torch.rand(16, 300, 32)\n",
    "    assert (attn(a)[0].shape == (16,300,32))\n",
    "\n",
    "test_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gY_nbtA-2Sl3"
   },
   "source": [
    "# Part IV. Build a Transformer Encoder\n",
    "\n",
    "Based on self-attention we can now build the fundamental building block of the transformer. You will implement the class `Block` first and then use it in the class `TransformerEncoder` to put together the full encoder.\n",
    "\n",
    "- **Important Note:** In contrast to the originally proposed model, we apply normalization (layer norm) before and **not** after the self-attention module. This is the only fundamental change that was found to improve the transformer architecture. Apart from this, most recent transformer models have the same structure.\n",
    "\n",
    "We have a class called `Block` which encapsulates all the logic of each block, as detailed in Figure 1 of the transformer [paper](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "To cross check you model, running the following command should give you the expected output.\n",
    "```python\n",
    "print(TransformerEncoder(dim=64, blocks=1, num_heads=8,  mlp_ratio=4., drop=0., dropout=0.))\n",
    "```\n",
    "\n",
    "```python\n",
    "TransformerEncoder(\n",
    "  (layers): ModuleList(\n",
    "    (0): Block(\n",
    "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
    "      (attn): Attention(\n",
    "        (qkv): Linear(in_features=64, out_features=192, bias=False)\n",
    "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
    "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
    "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
    "      (mlp): Mlp(\n",
    "        (fc1): Linear(in_features=64, out_features=256, bias=True)\n",
    "        (act): ReLU()\n",
    "        (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
    "        (drop): Dropout(p=0.0, inplace=False)\n",
    "      )\n",
    "    )\n",
    "  )\n",
    ")\n",
    "```\n",
    "\n",
    "Use the `drop` parameter for all dropout-layers, except for the `attn_drop` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2OyY124wATy",
    "outputId": "da956e19-f6e8-4f57-b058-601ffa972cf7"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., drop=0., attn_drop=0., actv_func=nn.ReLU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x, return_attention=False):\n",
    "        ### START CODE HERE ### (approx. 6 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"Stacks together multiple blocks to form a transformer encoder.\"\"\"\n",
    "    def __init__(self, dim, blocks=6, num_heads=8,  mlp_ratio=4., drop=0., attn_drop=0. ):\n",
    "        ### START CODE HERE ### (approx. 7 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "print(TransformerEncoder(dim=64, blocks=1, num_heads=8,  mlp_ratio=4., drop=0., attn_drop=0.))\n",
    "\n",
    "def test_transformer_encoder():\n",
    "    \"\"\"\n",
    "    Test the TransformerEncoder for shape errors\n",
    "    \"\"\"\n",
    "    encoder = TransformerEncoder(dim=64, blocks=1, num_heads=8,  mlp_ratio=4., drop=0., attn_drop=0.)\n",
    "    a = torch.rand(16,300,64)\n",
    "    assert (encoder(a).shape == (16,300,64))\n",
    "\n",
    "test_transformer_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9KQobfC7g2M"
   },
   "source": [
    "# Part V. Build the whole transformer model\n",
    "\n",
    "So far, we haven't implemented how the model is getting the input and how the final output for the classification task is produced.\n",
    "\n",
    "**Task:**\n",
    "- The inputs are just words mapped to indices from 0 to vocabulary size. Implement an embedding that the model can process. Check out `torch.nn.Embedding()`.\n",
    "- Second, you need to add the positional encodings that we have created.\n",
    "- Third, add the `TransformerEncoder` class.\n",
    "- Next, we need to aggregate the information from the encoder output. Use the GAP module, which does nothing but averaging all the token representations.\n",
    "- Finally, add the MLP class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwGbyI9A7g2M",
    "outputId": "919eb1ba-8e62-4dad-ad4c-b4432103142c"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, maxlen, vocab_size, blocks=4, num_heads=8,  mlp_ratio=4., drop=0., attn_drop=0., classes=2):\n",
    "        ### START CODE HERE ### (approx. 6 lines)\n",
    "         ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (approx. 5 lines)\n",
    "        ### END CODE HERE ###\n",
    "        return y\n",
    "\n",
    "def test_transformer_model():\n",
    "    device = 'cpu'\n",
    "    model = Transformer(d_model=32, maxlen=5000, vocab_size=50000, blocks=1, num_heads=2).to(device)\n",
    "    inp_data = next(iter(train_dataloader))[\"input_ids\"]\n",
    "    batch_size = inp_data.shape[0]\n",
    "    print('input shape:', inp_data.shape)\n",
    "    re = model(inp_data.to(device))\n",
    "    print('out shape:', re.shape)\n",
    "    assert re.shape == (batch_size,2)\n",
    "    print(model)\n",
    "\n",
    "test_transformer_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op6I2lnunZCh"
   },
   "source": [
    "# Part VI. Train the tranformer and plot the results\n",
    "\n",
    "**Task:** Test your implementation! Based on my implementation one can reach ~85% in the first 20-25 epochs.\n",
    "\n",
    "**Optional:** Given you have the time and resources, feel free to tune hyperparameters to see if you can increase validation accuracy. After how many epochs does the model overfit? Making a train/val acc plot will help you identify overfitting. How would you encounter overfit in such a case? Feel free to experiment more if you have the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942,
     "referenced_widgets": [
      "d6a0eadbda4a493e8cdd78e43940a235",
      "dea8f709920a41509cf7088be8a51562",
      "4fe79e57101a404a9f220a51bc9b0813",
      "122bd7e2592e451f885be9bc21bc15c7",
      "25aa71a914e84631a6d94919aaba6d70",
      "8d630959112642d6a22198e1870e7fc8",
      "7ec0d1c48c9c42489d87c4f9d1a73364",
      "d99aaa2e6a7e486ca1d11b8a4c94e076",
      "128b497f4f6046168a3388a654c408fb",
      "a33f02530c1440b8b0be6d19ac97c9f4",
      "ba3124af68364a00944c11fac6cf61f4"
     ]
    },
    "id": "rzubf2Ul7g2N",
    "outputId": "b6bd6c19-1acb-4607-9863-fa2a68caafd9"
   },
   "outputs": [],
   "source": [
    "def main(model):\n",
    "    ### START CODE HERE ### (approx. 6 lines)\n",
    "    ### END CODE HERE ###\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plot_stats(dict_log, baseline=85)\n",
    "    return dict_log\n",
    "\n",
    "### START CODE HERE ### (approx. 2 lines)\n",
    "### END CODE HERE ###\n",
    "dict_log = main(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Zsfk_5LnU0U"
   },
   "source": [
    "### Expected result\n",
    "\n",
    "![im1](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a11-12_transformer/figs/output_task6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnTuuyBUzt8n"
   },
   "source": [
    "# Part VII. Positional embeddings instead of sine positional encodings\n",
    "\n",
    "**Task:** Replace the sine positional encodings with positional embeddings. Encoding refers to a hard-coded transformation of the input, embedding to a learned one. For each position in the sequence, we use one trainable embedding vector. All you need to do here is to overwrite a small part of the `PositionalEncoding` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTQwjl7XnOPr"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(PositionalEncoding):\n",
    "    def __init__(self, d_model: int, dropout=0.1, max_len=5000):\n",
    "        ### START CODE HERE ### (approx. 2 lines)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "def test_PE():\n",
    "    PE = PositionalEmbedding(d_model=32, max_len=10000)\n",
    "    a = torch.rand(16,100,32)\n",
    "    print(PE(a).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIX61mYCKawe"
   },
   "source": [
    "# Part VIII. Retrain with positional embeddings.\n",
    "\n",
    "**Task:** Define the previous transformer with pos. embeddings and train it. For comparability, both models need to be trained with the same hyperparameters except positional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 910
    },
    "id": "U3fPdZKG7g2O",
    "outputId": "1028f674-130c-4034-f9c2-3c931db14a45"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 6 lines)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v354kMppnHe8"
   },
   "source": [
    "### Expected result\n",
    "\n",
    "![im1](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a11-12_transformer/figs/output_task8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOXoQXJd366A"
   },
   "source": [
    "# Bonus reads\n",
    "\n",
    "That's the end of the last exercise of the Deep learning Course. If you reached this point, congratulations!\n",
    "\n",
    "Endless research has been conducted on tranformers, positional embeddings, etc., especially in the computer vision area.\n",
    "If you are interested to delve into this topic further, here are some links:\n",
    "\n",
    "- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n",
    "- [How Transformers work in deep learning and NLP: an intuitive introduction by Nikolas Adaloglou](https://theaisummer.com/transformer/)\n",
    "- [Relative Positional Encoding](https://jaketae.github.io/study/relative-positional-encoding/)\n",
    "- [Transformer Architecture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)\n",
    "- [Transformers from Scratch](https://e2eml.school/transformers.html)\n",
    "- [Vision Transformer](https://paperswithcode.com/method/vision-transformer)\n",
    "- [An Image is Worth 16x16 Words, What is a Video Worth?](https://arxiv.org/abs/2103.13915)\n",
    "- [Demystifying efficient self-attention](https://towardsdatascience.com/demystifying-efficient-self-attention-b3de61b9b0fb)\n",
    "- [Why multi-head self attention works: math, intuitions and 10+1 hidden insights by Nikolas Adaloglou](https://theaisummer.com/self-attention/)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc5fcf396fe0abd4fa852aee332a0572494dcaf5776820055c87d9b84157f362"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05167a303cd24530bbb0c95cadb46819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "122bd7e2592e451f885be9bc21bc15c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a33f02530c1440b8b0be6d19ac97c9f4",
      "placeholder": "​",
      "style": "IPY_MODEL_ba3124af68364a00944c11fac6cf61f4",
      "value": " 25000/25000 [00:39&lt;00:00, 506.34 examples/s]"
     }
    },
    "128b497f4f6046168a3388a654c408fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "25aa71a914e84631a6d94919aaba6d70": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ec55e79b96c4a57b7d553ffc27d7fe2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d59af0304953408b9965ffc1202f7ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_3dc3b67c86f54d67b61aa369ede854a5",
      "value": " 25000/25000 [00:38&lt;00:00, 847.19 examples/s]"
     }
    },
    "3dc3b67c86f54d67b61aa369ede854a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fe79e57101a404a9f220a51bc9b0813": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d99aaa2e6a7e486ca1d11b8a4c94e076",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_128b497f4f6046168a3388a654c408fb",
      "value": 25000
     }
    },
    "574ab8215cb14322b82e0aa410292c02": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05167a303cd24530bbb0c95cadb46819",
      "max": 25000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89a0972611e341a598d846df26f91336",
      "value": 25000
     }
    },
    "73f6f54b84fd48be901c7803042fdf63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ec0d1c48c9c42489d87c4f9d1a73364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8395d106009048a98c28f5f1df9dac01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73f6f54b84fd48be901c7803042fdf63",
      "placeholder": "​",
      "style": "IPY_MODEL_8617475ba63d4b8c88cf8de88a5b3bef",
      "value": "Map: 100%"
     }
    },
    "8617475ba63d4b8c88cf8de88a5b3bef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89a0972611e341a598d846df26f91336": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d630959112642d6a22198e1870e7fc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e28231265924c1f892a466173385e0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8395d106009048a98c28f5f1df9dac01",
       "IPY_MODEL_574ab8215cb14322b82e0aa410292c02",
       "IPY_MODEL_2ec55e79b96c4a57b7d553ffc27d7fe2"
      ],
      "layout": "IPY_MODEL_fb1869fb2ad44100a6731f94cac0ea5a"
     }
    },
    "a33f02530c1440b8b0be6d19ac97c9f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba3124af68364a00944c11fac6cf61f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d59af0304953408b9965ffc1202f7ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6a0eadbda4a493e8cdd78e43940a235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dea8f709920a41509cf7088be8a51562",
       "IPY_MODEL_4fe79e57101a404a9f220a51bc9b0813",
       "IPY_MODEL_122bd7e2592e451f885be9bc21bc15c7"
      ],
      "layout": "IPY_MODEL_25aa71a914e84631a6d94919aaba6d70"
     }
    },
    "d99aaa2e6a7e486ca1d11b8a4c94e076": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea8f709920a41509cf7088be8a51562": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d630959112642d6a22198e1870e7fc8",
      "placeholder": "​",
      "style": "IPY_MODEL_7ec0d1c48c9c42489d87c4f9d1a73364",
      "value": "Map: 100%"
     }
    },
    "fb1869fb2ad44100a6731f94cac0ea5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
