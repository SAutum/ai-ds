{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fxawg0Tby_Lm"
   },
   "source": [
    "HHU Deep Learning, WS2023/24, 26.01.2024\n",
    "\n",
    "Lecture: Prof. Dr. Markus Kollmann\n",
    "\n",
    "Exercises: Nikolas Adaloglou, Felix Michels\n",
    "\n",
    "# Assignment 13 - Adversarial Attacks\n",
    "\n",
    "---\n",
    "\n",
    "Submit the solved notebook (not a zip) with your full name plus assignment number for the filename as an indicator, e.g `max_mustermann_a1.ipynb` for assignment 1. If we feel like you have genuinely tried to solve the exercise, you will receive 1 point for this assignment, regardless of the quality of your solution.\n",
    "\n",
    "## <center> DUE FRIDAY 02.02.2024 2:30 pm </center>\n",
    "\n",
    "Drop-off link: [https://uni-duesseldorf.sciebo.de/s/VmmJHs0Iws92Jyk](https://uni-duesseldorf.sciebo.de/s/VmmJHs0Iws92Jyk)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-iNAMeAy_Ln"
   },
   "source": [
    "This exercise is about Adversarial Attacks. Feel free to have a look at the original [paper](https://arxiv.org/abs/1412.6572) by Goodfellow before writing any code.\n",
    "\n",
    "### Some Tips and Remarks:\n",
    "\n",
    "* Use `torch.clamp` for the clip operations.\n",
    "* You can limit yourself to the first $1000$ images of the test set.\n",
    "* Do not copy code from anywhere.\n",
    "* Do not submit the checkpoints or datasets!\n",
    "* If you run into problems, let us know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8HlSZGvy_Ln"
   },
   "source": [
    "# Part I. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Prc-j_qA21H7",
    "outputId": "533cec65-2064-4a99-a317-d36671f92bfa"
   },
   "outputs": [],
   "source": [
    "!wget -c https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a13_adversarial_attack/data.tar.gz\n",
    "!tar xf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UKb3v_hy_Lo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG4bKZDxy_Lp"
   },
   "source": [
    "# Part II. Loading a pretrained ResNet18\n",
    "\n",
    "**Task:** Load the checkpoint `resnet18-cifar10.pth`and validate that the loaded model has a test accuracy of approximately $94\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khzg5MTdy_Lp",
    "outputId": "57d859c0-b685-46c8-f7ce-2ececceed3a6"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from models import ResNet18\n",
    "\n",
    "# Load the ResNet18 using the given checkpoint\n",
    "### START CODE HERE ### (approx. 4 lines)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojvBiJ8Xy_Lq"
   },
   "source": [
    "Initialise the CIFAR-10 dataset with dataloaders for the train and test sets. Choose the batch_size according to your system hardware. The input images are expected to be normalized to $[-1,1]$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ma0EtncMy_Lq",
    "outputId": "e960844c-fcf1-492e-85b9-03546851196e"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 7 lines)\n",
    "### END CODE HERE ###\n",
    "test_batch, test_labels = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8X8yfMWy_Lr"
   },
   "source": [
    "Implement the function below which calculates the model accuracy for a given dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUMdd15py_Lr"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(model, device, dataloader):\n",
    "    correct, total = 0, 0\n",
    "    ### START CODE HERE ### (approx. 4 lines)\n",
    "    ### END CODE HERE ###\n",
    "    return (correct/float(total)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87BFW_U8y_Lr",
    "outputId": "4f221c29-2e3f-41e9-e308-c41baff9e46e"
   },
   "outputs": [],
   "source": [
    "calc_accuracy(model, device, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIbPImfoy_Ls"
   },
   "source": [
    "# Part III. Fast-gradient-sign-method (FGSM)\n",
    "\n",
    "**Task:** Implement the fast gradient sign method (FGSM) as described in the [paper](https://arxiv.org/abs/1412.6572), section 4. Clip the values of the adversarial image to $[-1,1]$. Assume that the objective $J$ is the cross entropy loss.\n",
    "Do not modify the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKB7TMTNy_Ls"
   },
   "outputs": [],
   "source": [
    "def fgsm(model, device, batch, labels, epsilon):\n",
    "    \"\"\"\n",
    "    Returns adversarial examples of the batch\n",
    "    \"\"\"\n",
    "    batch = batch.to(device)\n",
    "    labels = labels.to(device)\n",
    "    ### START CODE HERE ### (approx. 5 lines)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOZr59diy_Ls"
   },
   "source": [
    "The fooling rate is the relative amount of adversarial images that resulted in a different prediction by the model. Plot different values of $\\epsilon$ against the resulting fooling rate on the test images in `test_batch`.\n",
    "\n",
    "Find a good value for $\\epsilon$ that results in a fooling rate of $70\\%$ on the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "Cpnlk2x6y_Lt",
    "outputId": "017e624a-e1eb-406e-89ef-ecf46608a6d0"
   },
   "outputs": [],
   "source": [
    "fooling_rates = []\n",
    "predictions = model(test_batch.to(device)).argmax(1)\n",
    "### START CODE HERE ### (approx. 5 lines)\n",
    "### END CODE HERE ###\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(torch.linspace(0,0.4,20), fooling_rates)\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Fooling Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_M4Kha7O2lT4"
   },
   "source": [
    "### Expected Result\n",
    "\n",
    "![fooling_rate.png](https://github.com/HHU-MMBS/Deep-Learning-Exercise-Extras/raw/main/a13_adversarial_attack/figs/fooling_rate.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nnWMMDwCy_Lt",
    "outputId": "970d00e8-1457-44b2-f0e1-41f4483dcddd"
   },
   "outputs": [],
   "source": [
    "# Run the fgsm function with your epsilon\n",
    "### START CODE HERE ### (approx. 1 lines)\n",
    "### END CODE HERE ###\n",
    "perturbations = advs - test_batch\n",
    "\n",
    "adv_predictions = model(advs.to(device)).argmax(1)\n",
    "predictions = model(test_batch.to(device)).argmax(1)\n",
    "(adv_predictions != predictions).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tR2uluzdy_Lt"
   },
   "source": [
    "Visualize at least $10$ adversarial images and compare them with the original images. Can you recognize the adversarial perturbations?\n",
    "\n",
    "Check out `torchvision.utils.make_grid` for good-looking plots here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "1qEHVhOby_Lu",
    "outputId": "e40d1eae-6547-4296-8dc0-b33680906249"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 7 lines)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad_WZtlyy_Lu"
   },
   "source": [
    "# Part IV. Basic Iterative Method (BIM)\n",
    "\n",
    "An extension of FGSM is the basic iterative method (BIM) as proposed in this [paper](https://arxiv.org/abs/1607.02533).\n",
    "\n",
    "**Task:** Implement targeted BIM as described in Section 2.3 of the paper. This method expects a target label as additional input and will change the image in a way that the classifier will output this target label for the adversarial image if the attack was successful. Again, clip the values of the adversarial image to $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-PT_SJzy_Lv"
   },
   "outputs": [],
   "source": [
    "def bim(model, device, data, step_size, steps=20, epsilon=0.05):\n",
    "    data = data.to(device)\n",
    "    ### START CODE HERE ### (approx. 11 lines)\n",
    "    ### END CODE HERE ###\n",
    "    return advs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBOzfP_ry_Lv"
   },
   "source": [
    "Tune the hyperparameters of the attack such that the fooling rate is above 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwChFKVay_Lv"
   },
   "outputs": [],
   "source": [
    "# Run the bim function\n",
    "### START CODE HERE ### (approx. 1 lines)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUdrYRCTy_Lv",
    "outputId": "b6db15cf-aba3-43e8-bbb3-381639229f4d"
   },
   "outputs": [],
   "source": [
    "perturbations_bim = advs_bim - test_batch\n",
    "adv_predictions = model(advs_bim.to(device)).argmax(1).cpu()\n",
    "torch.mean((adv_predictions != test_labels).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGvRY7iUy_Lw"
   },
   "source": [
    "Again, visualize the adversarial images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "er14RQ4Jy_Lw",
    "outputId": "2d965196-e7dd-4d9a-e70d-72492e0b6bfb"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 7 lines)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52nbMthQy_Lx"
   },
   "source": [
    "Compare the resulting perturbation norm with the perturbation norm of the adversarial images produced by FGSM, and plot both perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "V2nI7liPy_Lx",
    "outputId": "92e2225e-259a-496d-a4e6-d11fa99a0201"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (approx. 7 lines)\n",
    "### END CODE HERE ###"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
