{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929c0d85",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project 02 - Image segmentation and object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdc65e-b0ec-4d6e-89b8-bf5d92d9026b",
   "metadata": {},
   "source": [
    "__Handout date:__ 23.05.2024  \n",
    "__Submission deadline:__ 19.06.2024 - 23:59  \n",
    "__Topics:__ Segmentation and object detection.  \n",
    "__Submission link:__ https://fz-juelich.sciebo.de/s/410NfCTI5rMLv1n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8253429",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this project, we would like you to investigate image segmentation and object detection.\n",
    "For this, you will use the data from the [Broad Bioimage Benchmark Collection](https://bbbc.broadinstitute.org/BBBC039).\n",
    "The dataset contains images of cells acquired using fluorescence microscopy, along with annotations of individual cells.\n",
    "Your goal will be to apply the segmentation and detection methods described in the lecture to the dataset.\n",
    "\n",
    "__Note:__ The main goal of this project to get you working on a real-world segmentation/detection task. Projects will not be graded based on the performance of the trained classifiers.\n",
    "\n",
    "![A stack of images](./broad_dataset.png)\n",
    "\n",
    "We suggest that you follow the following  steps:\n",
    "1. __Know your data__ Have a look  at the resources provided on the website to understand the dataset.\n",
    "1. Download and inspect the images, groundtruth annotations, and metadata. Plot a few example datapoints. __Tip:__ The data has fixed URLs, so you can download the data from within the notebook (e.g., using `!wget URL`).\n",
    "1. Write a data loader that allows you to use the data in PyTorch. Split the data according to the training, test, and validation files provided in the metadata.\n",
    "1. Train one or multiple of the segmentation models discussed in the lecture (or any other segmentation model you would like to try) to segment the cells. Report the loss curve, appropriate quality metrics, and some example results of the trained model(s). \n",
    "1. Train one of multiple of the detection models discussed in the lecture (or any other detection method you would like to try) to detect the cells. Report the loss curve, appropriate quality metrics, and some example results of the trained model(s). \n",
    "\n",
    "Tipps and hints:\n",
    "1. Please do not add the dataset to your submission. Use `.gitignore` to ignore the directory containing the downloaded dataset.\n",
    "1. Think about how you have to process the provided groundtruth data to make it usable for segmentation and detection.\n",
    "1. `scikit-image` provides several helpful functions for extracting information from masks. Have a look at `skimage.measure.label` and `skimage.measure.regionprops`. These can help to convert data into a format that is appropriate for detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed7125-6c72-4873-ab86-a3fdc89cee74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
