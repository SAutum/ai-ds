{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d960cd7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise sheet 3\n",
    "\n",
    "__Handout date:__ 20.06.2024      \n",
    "__Submission deadline:__ 03.07.2024 - 23:59  \n",
    "__Topics:__ 3D reconstruction.  \n",
    "__Submission link:__ https://fz-juelich.sciebo.de/s/Z46ZvFOKA5t1MtD\n",
    "\n",
    "Add your answers by inserting cells under the given tasks. Keep your answers brief and clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4b150-1a56-413a-8aea-1797b891bf80",
   "metadata": {},
   "source": [
    "## Two view geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784d075-8089-4bbb-86b5-6efbeb6b7af3",
   "metadata": {},
   "source": [
    "-- __Task:__ Which steps are required to capture 3D models using cameras?\n",
    "\n",
    "1. Take overlapping images of the scene\n",
    "2. Find camera orientations in the „world“ coordinate system\n",
    "3. Find corresponding points and their 3D positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d7448-2500-430d-8f3a-93f148e9cae6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "-- __Task:__ Describe the degrees of freedom contained in epipolar geometry.\n",
    "\n",
    "2 degrees of freedom for the translation between the cameras and 3 degrees of freedom for the rotation between camers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d81ab-2f8f-4203-aa3b-bdb91167c9b9",
   "metadata": {},
   "source": [
    "-- __Task:__ Name and describe the steps of camera calibration.\n",
    "\n",
    "1. Capture the known calibration target in different poses (variation of the extrinsic parameters)\n",
    "2. Detect features on the target in the images\n",
    "3. Finally jointly optimize camera intrinsics and extrinsics\n",
    "    * Closed-form solution\n",
    "    * Non-linear optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebf7af-3dee-45b4-bc5c-02def7fa2a4a",
   "metadata": {},
   "source": [
    "-- __Task:__ What are intrinsic camera parameters? \n",
    "\n",
    "Parameters describing the internal characteristics of the camera.\n",
    "* Focal length\n",
    "* Principal point\n",
    "* Skew coefficient\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d290d-77a1-4d21-8519-033eea2b003b",
   "metadata": {},
   "source": [
    "-- __Task:__ What are extrinsic camera parameters?\n",
    "\n",
    "Extrinsic parameters describe the relation of the camera to some world coordinate system.\n",
    "* Translation vector\n",
    "* Rotation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9edbda-7dfc-479b-86c1-69a4aef3d7fd",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda16539-b1c5-439e-a1a3-95bb80e9508a",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the goal of triangulation?\n",
    "\n",
    "By intersecting two lines, we can determine the 3D position of a point from two or more 2D images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26382b63-4b4b-422f-ae0c-5e24e8770ff2",
   "metadata": {},
   "source": [
    "-- __Task:__ Briefly describe the construction of the linear system used for triangulation?\n",
    "\n",
    "The wanted point X is once projected by camera 1 with P and once by camera 2 with P'. Thus we get x = PX and x' = PX'. Combining these two equations we can construct a least-squares solution from SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a29d8-501e-40b5-9735-8755a81ae68b",
   "metadata": {},
   "source": [
    "-- __Task:__ Briefly explain why triangulation relies on a second camera to find the 3D point of an object.\n",
    "\n",
    "Using only one image, we can determine the position of the point only up to a scalar on a line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753b2bc-0f42-46d4-b9d2-1d7b4048fe95",
   "metadata": {},
   "source": [
    "## Epipolar geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be007c-1446-409c-9eee-7f2d31bde10d",
   "metadata": {},
   "source": [
    "-- __Task:__ Which points define the epipolar plane and the baseline?\n",
    "\n",
    "The baseline is the line between the two optical centers of two cameras.\n",
    "\n",
    "The epipolar plane is defined by the two optical centers and some point of interest X."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462249d-dd21-4d0a-87cd-82dbb0a01c9e",
   "metadata": {},
   "source": [
    "-- __Task:__ Which points define the epipoles?\n",
    "\n",
    "The epipoles are the projection of the optical centers onto the other image plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63225b-456b-4904-972c-ed83db2600ee",
   "metadata": {},
   "source": [
    "-- __Task:__ How is the epipolar line defined?\n",
    "\n",
    "The epipolar line is the intersection of the image plane and the epipolar plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4404c-0d72-4d31-beb5-c2e008f9d362",
   "metadata": {},
   "source": [
    "-- __Task:__ What is purpose of the essential matrix?\n",
    "\n",
    "The essential matrix encodes the epipolar geometry.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290fef2a-f81f-4764-8397-da7f2121e414",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the difference between an essential matrix and a homography? \n",
    "\n",
    "An essential matrix transforms a point onto a line. A homography transforms a point onto a point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859e4de-504b-4910-92df-12173069a35e",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the fundamental matrix?\n",
    "\n",
    "The fundemental matrix extends the essential matrix into pixel coordinates instead of camera coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b926f-66b3-46c3-b236-71348b9557e2",
   "metadata": {},
   "source": [
    "-- __Task:__ How many points are necessary to estimate the fundamental matrix?\n",
    "\n",
    "Eight points, implemented in the eight-point algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bcb57-82bc-4541-8f82-1c3123737f67",
   "metadata": {},
   "source": [
    "## Stereo reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc92cbb-54f8-427a-98f3-b4fe207aa99a",
   "metadata": {},
   "source": [
    "-- __Task:__ Which spatial properties can be derived from a sparse 3D point cloud created by stereo reconstruction, and which cannot?\n",
    "\n",
    "We can derived:\n",
    "* Relative distances and depth\n",
    "* Surface geometry\n",
    "\n",
    "We cannot derive:\n",
    "* Fine Details\n",
    "* Absolute distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec64c2d-8bfe-403b-a05c-056686846de4",
   "metadata": {},
   "source": [
    "-- __Task:__ Define the idea of rectification in stereo reconstruction.\n",
    "\n",
    "We want both cameras to face the same direction and the image planes should be parallel to the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1ede3-57b9-47b1-a7a8-eb1709f98cf2",
   "metadata": {},
   "source": [
    "-- __Task:__ What beneficial property can be found in rectified images?\n",
    "\n",
    "In rectified images all epipolar lines are horizontal and in the same pixel row. The matching between the two images becomes much easier with this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571883d4-7f4c-44d4-9a75-8fdabb89e7e0",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the disparity?\n",
    "\n",
    "The relative horizontal displacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e93f86-00ed-4767-84e8-6deaf2984b29",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the relationship between disparity and depth?\n",
    "\n",
    "Disparity and depth are inverse proportional. The higher the disparitiy, the closer the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bad6e8-50be-4703-96d8-0702320814cc",
   "metadata": {},
   "source": [
    "-- __Task:__ Which kinds of pixel movements can be observed in rectified images, and how do they relate to depth?\n",
    "\n",
    "In rectified images we can find horizontal displacements which are the disparity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da220e-a514-4080-9501-6c34461e0969",
   "metadata": {},
   "source": [
    "-- __Task:__ Briefly describe the process of stereo matching.\n",
    "\n",
    "* Rectify the images.\n",
    "* Match along the scanline.\n",
    "* Calculate the disparity.\n",
    "* Estimate the depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f90069-6980-44ad-af83-a650b24bb610",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the advantage of using rectified images for stereo matching?\n",
    "\n",
    "The search for matching points is simplified, because we only need to look in the same horizontal line. With this we can finde a match for (almost) every pixel in each image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b92f6-ffb4-499c-a54f-a516c2f6c462",
   "metadata": {},
   "source": [
    "-- __Task:__ What is a simple approach to avoid incorrect matches in stereo matching?\n",
    "\n",
    "Match the points in both directions, and only keep them if they are both valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d090497-3780-461f-b3fa-4455d7c8e1f7",
   "metadata": {},
   "source": [
    "-- __Task:__ What are possible sources of \"holes\" in depth/disparity images retrieved from stereo matching?\n",
    "\n",
    "* Occlusions\n",
    "* Textureless regions\n",
    "* Repetitions\n",
    "* Reflective surfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd15b0e-c71b-49a1-afba-54579adb9db7",
   "metadata": {},
   "source": [
    "-- __Task:__ What makes graphical models a suitable approach to resolve these holes?\n",
    "\n",
    "Graphical models enable to constraint the disparity of each pixel by the disparity of neighbouring pixels. This encourages the model to find a smooth solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d8b8b-403a-45bd-87ae-3f3f80550848",
   "metadata": {},
   "source": [
    "## Graphical models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fa1e3-172b-4bbc-9844-b5cdbdd8e794",
   "metadata": {},
   "source": [
    "-- __Task:__ Describe the two types of costs that are optimized in a graphical model.\n",
    "\n",
    "1. Unary terms or data terms\n",
    "2. Clique terms, defining the relation between pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a0332-4e6c-4c65-8e7c-534090ce99d0",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the difference between a directed and an undirected graphical model?\n",
    "\n",
    "In directed graphical model each edge has a direction. In undirected graph models all edges work the same in both directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb49b74-98ba-4416-ac51-1050d1c39424",
   "metadata": {},
   "source": [
    "-- __Task:__ Name an example for a directed grapical model.\n",
    "\n",
    "Bayesian networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2a4bb-080a-4451-9c53-07ff4016fdc2",
   "metadata": {},
   "source": [
    "-- __Task:__ What is a clique in a graphical model?\n",
    "\n",
    "A clique is a subset of nodes in the graph that are fully connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184e53c-9cfd-4f71-82c6-c851f56cb325",
   "metadata": {},
   "source": [
    "-- __Task:__ What is a maximum clique in a graphical model?\n",
    "\n",
    "A maximum clique is a clique to which no further node can be added without violating the property of a clique (full connection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926727b4-86c4-4133-ad5e-f87f7a641587",
   "metadata": {},
   "source": [
    "-- __Task:__ What are potentials and joint potentials?\n",
    "\n",
    "Potentials are non-negative functions of a variable x.\n",
    "Joint potentials are defined over two or more variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db69c2-2efa-47f2-ac6b-078d350919b9",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the definition of a Markov Random Field (MRF)?\n",
    "\n",
    "A markov random field is the product over the potentials over some cliques and variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
