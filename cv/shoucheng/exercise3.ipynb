{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d960cd7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise sheet 3\n",
    "\n",
    "__Handout date:__ 20.06.2024      \n",
    "__Submission deadline:__ 03.07.2024 - 23:59  \n",
    "__Topics:__ 3D reconstruction.  \n",
    "__Submission link:__ https://fz-juelich.sciebo.de/s/Z46ZvFOKA5t1MtD\n",
    "\n",
    "Add your answers by inserting cells under the given tasks. Keep your answers brief and clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4b150-1a56-413a-8aea-1797b891bf80",
   "metadata": {},
   "source": [
    "## Two view geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784d075-8089-4bbb-86b5-6efbeb6b7af3",
   "metadata": {},
   "source": [
    "-- __Task:__ Which steps are required to capture 3D models using cameras?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58516bdf-cec7-4e43-84b6-6b10405bf39c",
   "metadata": {},
   "source": [
    "1. Take overlapping images of the scene;\n",
    "2. Find camera orientation in the world cooridinate system;\n",
    "3. Find correponding points and their 3D positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d7448-2500-430d-8f3a-93f148e9cae6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "-- __Task:__ Describe the degrees of freedom contained in epipolar geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf0fd7-1d24-4c7f-91b3-bbb8a055302e",
   "metadata": {},
   "source": [
    "Contains:\n",
    "1. 2 degrees of freedom for translation;\n",
    "2. 3 degrees of freedom for rotation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d81ab-2f8f-4203-aa3b-bdb91167c9b9",
   "metadata": {},
   "source": [
    "-- __Task:__ Name and describe the steps of camera calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571cfbe-69ee-45aa-ae68-74f8226002a3",
   "metadata": {},
   "source": [
    "1. Capture target in different poses;\n",
    "2. Detect the features of the target in the images;\n",
    "3. Optimize the camera intrinsics and extrinsics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebf7af-3dee-45b4-bc5c-02def7fa2a4a",
   "metadata": {},
   "source": [
    "-- __Task:__ What are intrinsic camera parameters? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cbc3e4-0ff7-4924-81e9-8f4d0ddbf734",
   "metadata": {},
   "source": [
    "It is camera's internal parameters, such as focal length, aperture, pixel size, principle points..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d290d-77a1-4d21-8519-033eea2b003b",
   "metadata": {},
   "source": [
    "-- __Task:__ What are extrinsic camera parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688528ee-19a6-4f86-b6ff-5d0d1beb96ba",
   "metadata": {},
   "source": [
    "1. Coordinates of points in world coordinate system;\n",
    "2. Center of the projection in cameral coordinate system;\n",
    "3. Translation between the origin of world coordinate system and camera coordinate system;\n",
    "4. Rotation from world coordinate system to camera coordinate system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9edbda-7dfc-479b-86c1-69a4aef3d7fd",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda16539-b1c5-439e-a1a3-95bb80e9508a",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the goal of triangulation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9757ed1-8aad-4032-a5ef-ebb016a2956b",
   "metadata": {},
   "source": [
    "To find a 3D point given it's 2D projections onto mutiple images taken at different positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fd2e8-10f1-4cd2-b876-af52fd5de501",
   "metadata": {},
   "source": [
    "-- __Task:__ Briefly describe the construction of the linear system used for triangulation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5232319-e7a4-45b9-8e7c-8cf276d3d697",
   "metadata": {},
   "source": [
    "1. Estimate the unknown 3D point **X** with the formulation A**X** = 0 using cross product (**x** Ã— P**X**);\n",
    "2. From the formulation above we could get 2 constrain equations with respect to **X** in one camera;\n",
    "3. We introduce the 2nd camera with projection matrix $P^{'}$ and **$x^{'}$**, get another 2 constrain equations;\n",
    "4. Find a least square solution of the 4 equations above by singular value decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4a29d8-501e-40b5-9735-8755a81ae68b",
   "metadata": {},
   "source": [
    "-- __Task:__ Briefly explain why triangulation relies on a second camera to find the 3D point of an object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251fa58e-c991-45dd-aea9-ff790f7706a1",
   "metadata": {},
   "source": [
    "Because we need at least 2 points to fix the position of intersection point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2753b2bc-0f42-46d4-b9d2-1d7b4048fe95",
   "metadata": {},
   "source": [
    "## Epipolar geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be007c-1446-409c-9eee-7f2d31bde10d",
   "metadata": {},
   "source": [
    "-- __Task:__ Which points define the epipolar plane and the baseline?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4bbd7-3bf8-4410-b656-f73b8bd2125c",
   "metadata": {},
   "source": [
    "Optical centers of 2 cameras, and their corresponding epipoles, target 3D point **X**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462249d-dd21-4d0a-87cd-82dbb0a01c9e",
   "metadata": {},
   "source": [
    "-- __Task:__ Which points define the epipoles?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d705c19-dc51-4ab4-a68d-57014cc41d12",
   "metadata": {},
   "source": [
    "Optical centers of 2 cameras define the epipoles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63225b-456b-4904-972c-ed83db2600ee",
   "metadata": {},
   "source": [
    "-- __Task:__ How is the epipolar line defined?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244badc0-1446-4c7d-8e2a-bd5aae2e656c",
   "metadata": {},
   "source": [
    "It's defined by two points: epipole and the projection of X on image plane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f4404c-0d72-4d31-beb5-c2e008f9d362",
   "metadata": {},
   "source": [
    "-- __Task:__ What is purpose of the essential matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c686ee-4930-4de6-bb9b-77f68890dd3e",
   "metadata": {},
   "source": [
    "For a given point in one image, it helps us to find the corresponding epipolar line in the second image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290fef2a-f81f-4764-8397-da7f2121e414",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the difference between an essential matrix and a homography? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df62686-c37c-422f-a936-130e0ea9ef0d",
   "metadata": {},
   "source": [
    "Essential matrix maps a point to a line, while homography map a point to a point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859e4de-504b-4910-92df-12173069a35e",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the fundamental matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ccfdad-ef29-403e-b99a-d3e8acf7538c",
   "metadata": {},
   "source": [
    "$F = K^{'}EK^{-1}$, $K^{'}, K$ are the intrinsic calibration matrices of two cameras, E is the essential matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b926f-66b3-46c3-b236-71348b9557e2",
   "metadata": {},
   "source": [
    "-- __Task:__ How many points are necessary to estimate the fundamental matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5183f1a-5b3d-4da0-9fde-2afd4b8dd3f5",
   "metadata": {},
   "source": [
    "Since fundametal matrix has degree of freedom 7, 7 points are necessary to estimate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7bcb57-82bc-4541-8f82-1c3123737f67",
   "metadata": {},
   "source": [
    "## Stereo reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc92cbb-54f8-427a-98f3-b4fe207aa99a",
   "metadata": {},
   "source": [
    "-- __Task:__ Which spatial properties can be derived from a sparse 3D point cloud created by stereo reconstruction, and which cannot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec64c2d-8bfe-403b-a05c-056686846de4",
   "metadata": {},
   "source": [
    "-- __Task:__ Define the idea of rectification in stereo reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3c3750-d995-4421-8bb8-3ae205d91d3e",
   "metadata": {},
   "source": [
    "Rewarp one camera such that two cameras are aligned to be coplanar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1ede3-57b9-47b1-a7a8-eb1709f98cf2",
   "metadata": {},
   "source": [
    "-- __Task:__ What beneficial property can be found in rectified images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea69bd-3d57-4f52-8196-6c464790d6ad",
   "metadata": {},
   "source": [
    "Correspondences are located on the same image row as querypoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571883d4-7f4c-44d4-9a75-8fdabb89e7e0",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the disparity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624ab3e-8367-40a6-b1fe-900e876337e3",
   "metadata": {},
   "source": [
    "Relative horizontal displacement in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e93f86-00ed-4767-84e8-6deaf2984b29",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the relationship between disparity and depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0772e00e-705a-4326-af35-c4aaea6501cc",
   "metadata": {},
   "source": [
    "Disparity is antiproportional to depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bad6e8-50be-4703-96d8-0702320814cc",
   "metadata": {},
   "source": [
    "-- __Task:__ Which kinds of pixel movements can be observed in rectified images, and how do they relate to depth?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c72d89-c999-4726-a0a4-0658fb01ea5a",
   "metadata": {},
   "source": [
    "Horizontal displacement can be observed. It is antiproportional to depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da220e-a514-4080-9501-6c34461e0969",
   "metadata": {},
   "source": [
    "-- __Task:__ Briefly describe the process of stereo matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff5f3f-c1e7-4e00-a520-8dc3f4d6b556",
   "metadata": {},
   "source": [
    "Match a patch in the first image by computing similarities of patches in the second image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f90069-6980-44ad-af83-a650b24bb610",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the advantage of using rectified images for stereo matching?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92947d69-f159-45eb-bcb0-5926f8b1d562",
   "metadata": {},
   "source": [
    "The patches in the second image to be computed are in the horizontal shift row of the patch in the first image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b92f6-ffb4-499c-a54f-a516c2f6c462",
   "metadata": {},
   "source": [
    "-- __Task:__ What is a simple approach to avoid incorrect matches in stereo matching?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f634375-a612-44b0-aa2a-70dcb58b2a16",
   "metadata": {},
   "source": [
    "Block matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d090497-3780-461f-b3fa-4455d7c8e1f7",
   "metadata": {},
   "source": [
    "-- __Task:__ What are possible sources of \"holes\" in depth/disparity images retrieved from stereo matching?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654cb680-dd87-4771-b83e-70a17b27a03a",
   "metadata": {},
   "source": [
    "Occlusions, slanted surfaces, repetitve patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd15b0e-c71b-49a1-afba-54579adb9db7",
   "metadata": {},
   "source": [
    "-- __Task:__ What makes graphical models a suitable approach to resolve these holes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0ece07-f91b-4956-a4ac-a8d4476caeac",
   "metadata": {},
   "source": [
    "It minimizes the smoothness cost (neighboring pixels usually lead to similar depth estimates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d8b8b-403a-45bd-87ae-3f3f80550848",
   "metadata": {},
   "source": [
    "## Graphical models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6fa1e3-172b-4bbc-9844-b5cdbdd8e794",
   "metadata": {},
   "source": [
    "-- __Task:__ Describe the two types of costs that are optimized in a graphical model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01798903-7d4d-4fac-9dcc-60ca1922c3af",
   "metadata": {},
   "source": [
    "Data cost at each pixel and smoothness cost at each neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a0332-4e6c-4c65-8e7c-534090ce99d0",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the difference between a directed and an undirected graphical model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83de845-5e66-421e-ade3-45030f4cdf81",
   "metadata": {},
   "source": [
    "Undirected graphical model can be used for bidirectional and symmetric dependencies, while directed graphical models are used for asymmetric dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb49b74-98ba-4416-ac51-1050d1c39424",
   "metadata": {},
   "source": [
    "-- __Task:__ Name an example for a directed grapical model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3d40b-328f-4ea3-a1ab-dafb3a92b0f2",
   "metadata": {},
   "source": [
    "Bayesian network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd2a4bb-080a-4451-9c53-07ff4016fdc2",
   "metadata": {},
   "source": [
    "-- __Task:__ What is a clique in a graphical model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61153ad-00cb-44f7-9621-1005ed3d9d39",
   "metadata": {},
   "source": [
    "It is a subset of vertices of an undirected graph such that every two distinct vertices in the clique are adjacent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184e53c-9cfd-4f71-82c6-c851f56cb325",
   "metadata": {},
   "source": [
    "-- __Task:__ What is a maximum clique in a graphical model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f57ff-4f3c-4478-8f5e-7cceb55b59b7",
   "metadata": {},
   "source": [
    "It is a clique that cannot be extended by including one more adjacent vertex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926727b4-86c4-4133-ad5e-f87f7a641587",
   "metadata": {},
   "source": [
    "-- __Task:__ What are potentials and joint potentials?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d13dc4-d09e-4b6f-a163-1198ab45de57",
   "metadata": {},
   "source": [
    "Potentials are non-negative functions of a variable. Joint potentials are joint distribution of multiple variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db69c2-2efa-47f2-ac6b-078d350919b9",
   "metadata": {},
   "source": [
    "-- __Task:__ What is the definition of a Markov Random Field (MRF)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a18a0a-a570-4fb2-92ef-2dcb38e3a2d5",
   "metadata": {},
   "source": [
    "It is a probabilistic model over undirected graph which satisfies Markov properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
